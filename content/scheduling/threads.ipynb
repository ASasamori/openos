{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5840d-f280-474f-a222-4de9b686ecf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ecb89a-fd05-4417-b111-13bb20f8a717",
   "metadata": {
    "tags": []
   },
   "source": [
    "(cont:vp:threads)=\n",
    "# Threads: Virtual CPU\n",
    "\n",
    "If a process is a *virtual computer*, a **thread** is a *virtual CPU*.  \n",
    "Modern computers have many CPUs, and many applications are written to exploit multiple *virtual CPU* either to enable progress to be made while some threads are blocked, or to enable the program to exploit multiple physical CPUs.  We call such applications multi-threaded applications.  All the **threads** are part of the same process, sharing memory, open files, etc... they only differ in the set of registers run on the CPU. \n",
    "\n",
    "One special case of a multi-threaded program is the kernel itself.  While many applications may run on a single CPU, the kernel has to run on all the CPUs.  The major challenge to write multi-threaded programs, of which the kernel is probably the most extreme example, is how to ensure that the threads that are running at the same time **synchronize** so that they don't modify the same memory in incompatible ways at the same time.  This is one of the most complex topics in operating systems, and we defer it to later (see [synchronization](cont:conc:intro)) after we have finished discussing memory management and file systems. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01ff62-d26e-433f-9c56-ac9b35e9d885",
   "metadata": {},
   "source": [
    "## Kernel level threads\n",
    "\n",
    "If you want to exploit multiple CPUs the easiest way is to have the abstraction of threads implemented by the kernel, just like processes.  You may have wondered why in {numref}`img:intro:proc` and {numref}`simple_task_struct` Linux refers to the internal data structures as *tasks* rather than processes.   The implementation of the thread abstraction in the Linux kernel is that each thread is its own task, with its own thread state, and all the threads in a process point to the same MM and file struct data structures.  With such a design, everything we have talked about context switching and scheduling in the context of processes really applies to threads, and the fact that multiple of these threads are part of a single process is irrelevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46f74b-dbff-4ad0-a0b1-d1a8dffb8eea",
   "metadata": {},
   "source": [
    "## User level threads\n",
    "\n",
    "You can also implement threads at user level. There are advantages to such implementation, where in user space one can quickly context switch between one thread and another. In fact, those of you taking EC440 at BU, you will be implementing your own user level threading system.  There is also vast literature of research that multiplexes some number of user level threads on top of some number of kernel threads. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
