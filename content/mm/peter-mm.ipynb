{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799990be-ce03-4aa7-a0c9-73dc060ffeaa",
   "metadata": {},
   "source": [
    "# Peter's Virtual Memory chapter\n",
    "\n",
    "In [\\[chap:osbasics\\]](#chap:osbasics){reference-type=\"autoref\"\n",
    "reference=\"chap:osbasics\"} we discussed operating systems basics such as\n",
    "I/O, program loading, and context switching primarily for a simple\n",
    "computer with a single *physical address space*. By this we mean that\n",
    "the bits in an address register---for instance the program counter---are\n",
    "the same bits that go out over wires on the motherboard to DIMM sockets\n",
    "and select a particular location in a memory chip, so that no matter\n",
    "what process is executing, the same address (e.g. 0x1000) always refers\n",
    "to the same memory location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbfa8b-8b6d-419a-82be-f2fb1386ccf1",
   "metadata": {},
   "source": [
    "## Base and Bounds translation\n",
    "\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-base-bounds.png)\n",
    "\n",
    "\n",
    "We first looked at direct physical addressing, where no matter which\n",
    "process is executing, the same address (e.g. 0x1000) refers to the same\n",
    "memory location. In addition we reviewed a very simple form of address\n",
    "translation, shown here in\n",
    "[\\[fig:vm:fig1\\]](#fig:vm:fig1){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig1\"}, where base and bounds registers are used to\n",
    "relocate a section of the *virtual address space*---the addresses seen\n",
    "by the program, corresponding to values in the CPU registers---to\n",
    "somewhere else in the physical address space. By changing these\n",
    "translations the operating system can create multiple virtual address\n",
    "spaces, one per process; however there is still only one physical\n",
    "address space, uniquely identifying each byte in each memory chip. In\n",
    "this chapter we introduce *paged address translation*, a more complex\n",
    "address translation mechanism used by most modern CPUs, and present the\n",
    "32-bit Intel implementation as an example.\n",
    "\n",
    "**Limitations of base+bound translation:** Modern hardware and operating\n",
    "systems provide a very similar process address space model, but no\n",
    "longer use base and bounds registers for address translation[^1] ,\n",
    "despite it being simple, cheap, and quite possibly faster than alternate\n",
    "methods. There are a number of reasons why base and bounds translation\n",
    "is no longer used, but the fundamental reason is memory fragmentation.\n",
    "\n",
    "Base and bounds address translation requires a contiguous memory region\n",
    "for each process. If memory is allocated and de-allocated in chunks of\n",
    "different sizes and at different times, then it can become *fragmented*\n",
    "so that even if large amounts of memory are free, it will be divided\n",
    "into smaller fragments, separated by longer-lived small allocations, as\n",
    "seen in [\\[fig:vm:fig2\\]](#fig:vm:fig2){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig2\"}.\n",
    "\n",
    "Start: 32 locations, all free\\\n",
    "![image](../images/pb-figures/mm/virt-mem-frag-1.png)\\\n",
    "\n",
    "Step 1, 2: a = alloc(10), b = alloc(1)\\\n",
    "![image](../images/pb-figures/mm/virt-mem-frag-2.png)\\\n",
    "\n",
    "Step 3, 4, 5: c = alloc(10), d = alloc(1), e = alloc(10)\\\n",
    "![image](../images/pb-figures/mm/virt-mem-frag-3.png)\\\n",
    "\n",
    "Step 6, 7, 8: free(a), free(c), free(e)\\\n",
    "![image](../images/pb-figures/mm/virt-mem-frag-4.png)\n",
    "\n",
    "In the last line, you can see that only 2 units of memory (out of 32)\n",
    "remain allocated, but the largest amount that can be allocated at one\n",
    "time is 10 units. If all allocation requests are small, this might not\n",
    "be a problem; however, in an operating system it is common to have one\n",
    "or two very large processes (e.g., a web browser and word processing\n",
    "software), and many small, long-running processes (e.g., the on-screen\n",
    "battery display or wifi signal strength indicator). In this case, large\n",
    "memory allocations may fail, even when there is enough total memory\n",
    "free, because long-lived small allocations fragment the available\n",
    "contiguous memory into smaller pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28d1dd-a67c-440a-be1b-76991a2b7f20",
   "metadata": {},
   "source": [
    "## Paging - Avoiding Fragmentation\n",
    "\n",
    "The fragmentation in\n",
    "[\\[fig:vm:fig2\\]](#fig:vm:fig2){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig2\"} is termed *external fragmentation*, because the\n",
    "memory wasted is *external* to the regions allocated. This situation can\n",
    "be avoided by *compacting* memory---moving existing allocations around,\n",
    "thereby consolidating multiple blocks of free memory into a single large\n",
    "chunk. This is a slow process, requiring processes to be paused, large\n",
    "amounts of memory to be copied, and base+bounds registers modified to\n",
    "point to new locations[^2].\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-map.png){height=\"8\\\\baselineskip\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77f731-9a19-43ed-9ce8-5b28e2919104",
   "metadata": {},
   "source": [
    "Instead, modern CPUs use *paged address translation*, which divides the\n",
    "physical and virtual memory spaces into fixed-sized pages, typically\n",
    "4KB, and provides a flexible mapping between virtual and physical pages,\n",
    "as shown in [\\[fig:vm:fig3\\]](#fig:vm:fig3){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig3\"}. The operating system can then maintain a list\n",
    "of free physical pages, and allocate them as needed. Because any\n",
    "combination of physical pages may be used for an allocation request,\n",
    "there is no external fragmentation, and a request will not fail as long\n",
    "as there are enough free physical pages to fulfill it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2781c-63a2-44e5-b2f0-802ea256f7a4",
   "metadata": {},
   "source": [
    "### Internal Fragmentation\n",
    "\n",
    "Paging solves the problem of external fragmentation, but it suffers from\n",
    "another issue, *internal fragmentation*, because space may be wasted\n",
    "*inside* the allocated pages. E.g. if 10 KB of memory is allocated in\n",
    "4KB pages, 3 pages (a total of 12 KB) are allocated, and 2KB is wasted.\n",
    "To allocate hundreds of KB in pages of 4KB this is a minor overhead:\n",
    "about $\\frac{1}{2}$ a page, or 2 KB, wasted per allocation. But internal\n",
    "fragmentation makes this approach inefficient for very small allocations\n",
    "(e.g. the `new` operator in C++), as shown in\n",
    "[\\[fig:vm:fig4\\]](#fig:vm:fig4){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig4\"}. (It is also one reason why even though most\n",
    "CPUs support multi-megabyte or even multi-gigabyte \"huge\" pages, which\n",
    "are slightly more efficient than 4 KB pages, they are rarely used.)\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic7.png){width=\"90%\"}\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000c32c-8c71-4351-8112-49b1a81077a5",
   "metadata": {},
   "source": [
    "## Paged Address Translation\n",
    "\n",
    "We examine a single model of address translation in detail: the one used\n",
    "by the original Pentium, and by any Intel-compatible CPU running in\n",
    "32-bit mode. It uses 32-bit virtual addresses, 32-bit physical\n",
    "addresses, and a page size of 4096 bytes. Since pages are $2^{12}$ bytes\n",
    "each, addresses can be divided into 20-bit page numbers and 12-bit\n",
    "offsets within each page, as shown in\n",
    "[\\[fig:vm:fig5\\]](#fig:vm:fig5){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig5\"}\n",
    "\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic10.png){height=\"5.5\\\\baselineskip\"}\n",
    "\n",
    "\n",
    "The Memory Management Unit (MMU) maps a 20-bit virtual page number to a\n",
    "20-bit physical page number; the offset can pass through unchanged, as\n",
    "shown in [\\[fig:vm:fig6\\]](#fig:vm:fig6){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig6\"}, giving the physical address the CPU should\n",
    "access.\n",
    "\n",
    "![Page number and offset in 32-bit paged translation with 4KB\n",
    "pages](../images/pb-figures/mm/virt-mem-pic9.png){#fig:vm:fig5 width=\"\\\\textwidth\"}\n",
    "\n",
    "Although paged address translation is far more flexible than base and\n",
    "bounds registers, it requires much more information. Base and bounds\n",
    "translation only requires two values, which can easily be held in\n",
    "registers in the MMU. In contrast, paged translation must be able to\n",
    "handle a separate mapping value for each of over a million virtual\n",
    "pages. (although most programs will only map a fraction of those pages)\n",
    "The only possible place to store the amount of information required by\n",
    "paged address translation is in memory itself, so the MMU uses page\n",
    "tables in memory to specify virtual-to-physical mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114ddc9-ee81-4475-a925-393b79d37e0a",
   "metadata": {},
   "source": [
    "### Single-level Page Table\n",
    "\n",
    "One of the simplest ways to structure a page table for mapping 20-bit\n",
    "page numbers is as a simple array with $2^{20}$ entries. With this\n",
    "configuration, each virtual page has an entry, and the value in that\n",
    "entry is the corresponding physical page number, as seen in\n",
    "[\\[fig:vm:fig11\\]](#fig:vm:fig11){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig11\"}. This single-level table is located in\n",
    "physical memory, and the MMU is given a pointer to this table, which is\n",
    "stored in an MMU register. (On Intel-compatible CPUs, the page table\n",
    "pointer is Control Register 3, or CR3.) This is shown in\n",
    "[\\[fig:vm:fig11\\]](#fig:vm:fig11){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:fig11\"}, where we see the first two entries in a\n",
    "$2^{20}$ or 1048576-entry mapping table. In addition to the translated\n",
    "page number, each entry contains a *P* bit to indicate whether or not\n",
    "the entry is \"present,\" i.e., valid. Unlike in C or Java we can't use a\n",
    "special null pointer, because 0 is a perfectly valid page number[^3].\n",
    "\n",
    "![Single-level 32-bit page\n",
    "table](../images/pb-figures/mm/virt-mem-pic11.png){#fig:vm:fig11 width=\"85%\"}\n",
    "\n",
    "In [\\[lst:map:pcode\\]](#lst:map:pcode){reference-type=\"autoref\"\n",
    "reference=\"lst:map:pcode\"} we see pseudo-code for the translation\n",
    "algorithm implemented in an MMU using a single-level table; VA and PA\n",
    "stand for virtual and physical addresses, and VPN and PPN are the\n",
    "virtual and physical page numbers.\n",
    "\n",
    "``` {#lst:map:pcode float=\"\" xleftmargin=\"12pt\" framexleftmargin=\"12pt\" caption=\"Address translation pseudo-code for single-level page table.\" label=\"lst:map:pcode\"}\n",
    "PA = translate(VA):\n",
    "            VPN, offset = split[20 bits, 12 bits](VA)\n",
    "            PTE = physical_read(CR3 + VPN*sizeof(PTE), sizeof(PTE))\n",
    "            if not PTE.present:\n",
    "                fault\n",
    "            return PTE.PPN + offset\n",
    "```\n",
    "\n",
    "Note that this means that every memory operation performed by the CPU\n",
    "now requires two physical memory operations: one to translate the\n",
    "virtual address, and a second one to perform the actual operation. If\n",
    "this seems inefficient, it is, and it will get worse. However, in a page\n",
    "or two we'll discuss the *translation lookaside buffer* or TLB, which\n",
    "caches these translations to eliminate most of the overhead.\n",
    "\n",
    "The single-level page table handles the problem of encoding the\n",
    "virtual-to-physical page map, but causes another: it uses 4 MB of memory\n",
    "per map. Years ago (e.g. in the mid-80s when the first Intel CPUs using\n",
    "this paging structure were introduced) this was entirely out of the\n",
    "question, as a single computer might have a total of 4 MB of memory or\n",
    "less. Even today, it remains problematic. As an example, when these\n",
    "notes were first written (2013), the most heavily-used machine in the\n",
    "CCIS lab (login.ccs.neu.edu) had 4 GB of memory, and when I checked it\n",
    "had 640 running processes. With 4 MB page tables and one table per\n",
    "process, this would require 2.5GB of memory just for page tables, or\n",
    "most of the machine's memory. Worse yet, each table would require a\n",
    "contiguous 4MB region of memory, running into the same problem of\n",
    "external fragmentation that paged address translation was supposed to\n",
    "solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dbe05-5533-4832-825c-d2d082abee9c",
   "metadata": {},
   "source": [
    "### 2-level Page Tables\n",
    "\n",
    "![Two-level page table for 32-bit addresses and 4 KB\n",
    "pages](../images/pb-figures/mm/virt-mem-pic12.png){#fig:vm:pic12 width=\"80%\"}\n",
    "\n",
    "To fix this, almost all 32-bit processors (e.g. Intel, ARM) use a\n",
    "2-level page table, structured as a tree, as seen in\n",
    "[\\[fig:vm:pic12\\]](#fig:vm:pic12){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic12\"}.\n",
    "\n",
    "The top ten bits of the virtual page number index into the top-level\n",
    "table (sometimes called the *page directory*), which holds a pointer to\n",
    "a second-level table. The bottom ten bits of the virtual page number are\n",
    "used as an index into this second-level table, giving the location where\n",
    "the actual physical address will be found. At first glance, it appears\n",
    "that this structure takes just as much space as a single-level table. To\n",
    "map a full 4 GB of memory, it still requires 4 MB (plus 1 additional\n",
    "page) for page tables. But if a process only needs a small amount of\n",
    "memory, most of the entries in the top-level directory will be empty\n",
    "(shown here as P=0), and only a small number of second-level tables will\n",
    "be needed; small-memory processes will thus have small page tables. And\n",
    "since the table is made out of individual pages, we can use whatever set\n",
    "of 4 KB pages are available, instead of needing a contiguous 4 MB block.\n",
    "\n",
    "Note that this is a key characteristic of almost every page table\n",
    "implementation: a page table is made up of pages, allowing the same pool\n",
    "of free pages to be used for both user memory allocation and for page\n",
    "tables themselves. In addition it means that each sub-table starts at\n",
    "the beginning of a page and fits within that page, which simplifies\n",
    "array lookups when translating a page number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efab991-c873-4f01-b327-c9ab753832ae",
   "metadata": {},
   "source": [
    "### 2-Level Page Table Operation\n",
    "\n",
    "In [\\[fig:vm:pic13\\]](#fig:vm:pic13){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic13\"} we see a page table constructed of 3 pages:\n",
    "physical pages 00000 (the root directory), 00001, and 00003. Two data\n",
    "pages are mapped: 00002 and 00004. Any entries not shown are assumed to\n",
    "be null, i.e., the present bit is set to 0. As an example we use this\n",
    "page table to translate a read from virtual address 0x0040102C.\n",
    "\n",
    "![2-level Page Table Example](../images/pb-figures/mm/virt-mem-pic13.png){#fig:vm:pic13\n",
    "width=\"90%\"}\n",
    "\n",
    "The steps involved in translating this address are:\n",
    "\n",
    "1\\) Split the address into page number and offset\n",
    "\n",
    "\\\n",
    "![image](../images/pb-figures/mm/virt-mem-pic14.png){width=\"0.35\\\\columnwidth\"}\n",
    "\n",
    "2\\) Split the page number into top and bottom 10 bits, giving `0x001`\n",
    "and `0x001`. (in the figure the top row is hex, the middle two rows are\n",
    "binary, and the bottom is hex again.)\n",
    "\n",
    "\\\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic15.png){width=\"0.9\\\\columnwidth\"}\n",
    "\n",
    "3\\) Read entry `[001]` from the top-level page directory (physical page\n",
    "`00000`) (note sizeof(entry) is 4 bytes):\\\n",
    "\n",
    "``` {xleftmargin=\"12pt\" framexleftmargin=\"12pt\"}\n",
    "address = start [00000000] + index [001] * sizeof(entry)\n",
    "read 4 bytes from physical address 00000004 (page 00000, offset 004)\n",
    "result = [p=1, pgnum = 00001]\n",
    "```\n",
    "\n",
    "4\\) Read entry `[001]` from the page table in physical page `00001`:\n",
    "\n",
    "``` {xleftmargin=\"12pt\" framexleftmargin=\"12pt\"}\n",
    "address = 00001000 + 001*4 = 00001004\n",
    "read 4 bytes from physical address 00001004\n",
    ":result = [p=1, pgnum = 00002]\n",
    "```\n",
    "\n",
    "This means that the translated physical page number is `00002`. The\n",
    "offset in the original virtual address is `02C`, so combining the two we\n",
    "get the final physical address, `0000202C`.\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "![Reference page table for review\n",
    "questions](../images/pb-figures/mm/virt-mem-pic16.png){#fig:vm:review1 width=\"95%\"}\n",
    "\n",
    "::: enumerate\n",
    ":::\n",
    "\n",
    "::: gsidebarN\n",
    "13 A famous computer science quote attributed to David Wheeler is: \"All\n",
    "problems in computer science can be solved by another level of\n",
    "indirection,\" to which some add \"except the performance problems caused\n",
    "by indirection.\" A corollary to this is that most performance problems\n",
    "can be solved by adding caching. How are these quotes applicable to\n",
    "paged address translation?\n",
    ":::\n",
    "\n",
    "## Translation Look-aside Buffers (TLBs)\n",
    "\n",
    "The 2-level table address translation processes you just learned about\n",
    "is highly inefficient, even more so than the single-level table. Even if\n",
    "MMU accesses to memory can be satisfied from the L1 cache, this will\n",
    "still slow down the CPU by a factor of three or more. To reduce this\n",
    "inefficiency, a special-purpose cache called the Translation Look-Aside\n",
    "Buffer (TLB) is introduced. Instead of holding memory values, like the\n",
    "L1 and L2 caches, the TLB holds virtual page number to physical page\n",
    "number mappings. The TLB is typically very small: examining the machines\n",
    "I have readily available, I see a TLB size ranging from 64 mappings (on\n",
    "certain Intel Atom CPUs) to 640 mappings on Core i7 and Xeon E7 CPUs.\n",
    "One reason for this small size is because the TLB has to be very\n",
    "fast---they are needed for every memory operation before the CPU can\n",
    "look in its cache for a value.\n",
    "\n",
    "Using the TLB, the translation process now looks like this:\n",
    "\n",
    "``` {#lst:vm:tlb caption=\"Paged address translation with TLB\" label=\"lst:vm:tlb\"}\n",
    "translate VA -> PA:\n",
    "    (VPN, offset) = split([20,12],VA)\n",
    "    if VPN is in TLB:\n",
    "        return TLB[VPN] + offset\n",
    "    (top10, bottom10) = split([10,10],VPN)\n",
    "    PDE = phys_read(CR3 + top10*4)\n",
    "    PTE = phys_read(PDE.pg<<12 + bottom10*4)\n",
    "    PPN = PTE.pg\n",
    "    add (VPN->PPN) to TLB, evicting another entry\n",
    "    return PPN + offset\n",
    "```\n",
    "\n",
    "where PDE is the page *directory* (i.e. top-level) entry, PTE is the\n",
    "page *table* (second-level) entry, and VPN, PPN are virtual and physical\n",
    "page numbers as before.\n",
    "\n",
    "How well does this perform? If all of the code and data fits into 640\n",
    "pages (about 2.5MB) on a high-end machine, all translations will come\n",
    "out of the TLB and there will be no additional overhead for address\n",
    "translation. If the *working set* (the memory in active use) is larger\n",
    "than this then some accesses will miss in the TLB and require page-table\n",
    "lookup in memory; however in most cases the translated mapping will be\n",
    "used many times before being evicted from the TLB, and the overhead of\n",
    "accessing in-memory page tables will be modest. (In addition, note that\n",
    "MMU accesses to the page table go through the cache, further speeding up\n",
    "the translation process)\n",
    "\n",
    "## TLB Consistency\n",
    "\n",
    "Like any other cache, a TLB only functions correctly if it is\n",
    "consistent, i.e. the entries in the TLB accurately reflect the in-memory\n",
    "values (i.e. page tables) which they are caching. Since the values\n",
    "loaded into the TLB come from a page table in memory at the address\n",
    "identified by CR3, the values may become invalid if either (a) the page\n",
    "table values in memory change (due to CPU writes) or (b) CR3 is\n",
    "modified, so that it points to a different page table. In other words,\n",
    "inconsistencies can arise due to:\n",
    "\n",
    "**Individual Entry Modifications:** Sometimes the OS must modify the\n",
    "address space of a running program, e.g. during demand paging (covered\n",
    "below), where the OS maps in new pages and un-maps others. When changing\n",
    "the page table in memory, the OS must ensure that the TLB is not caching\n",
    "a copy of the old entry.\n",
    "\n",
    "**Context switches:** The OS provides each process with a separate\n",
    "*virtual address space*, or set of virtual to physical mappings; the\n",
    "same virtual address may be mapped to a different physical memory\n",
    "location in each process. (i.e. to a memory location \"owned\" by that\n",
    "process.) When switching between processes the OS changes CR3 to point\n",
    "to the address space of the new process, and it's clearly important for\n",
    "both security and correctness to ensure that the MMU uses these\n",
    "mappings, not the old ones.\n",
    "\n",
    "### Preventing TLB Inconsistencies\n",
    "\n",
    "The issue of modifications can be solved in a fairly straightforward\n",
    "way: the MMU provides one instruction to flush the TLB entry for a\n",
    "particular page, and another to flush the entire TLB (e.g. if a large\n",
    "number of mappings are modified). When entries are flushed from the TLB,\n",
    "there is almost always a performance impact, because of the extra memory\n",
    "accesses needed to reload those entries the next time they are required.\n",
    "In this case, this overhead is not that significant, because (a) the OS\n",
    "is already spending a lot of time modifying the page table, and (b) it\n",
    "doesn't do this very often, anyway.\n",
    "\n",
    "However, the issue with context switches is harder to solve. The easy\n",
    "solution is to ignore the performance overhead and flush the entire TLB\n",
    "on every context switch, as is done on most Intel-compatible CPUs.\n",
    "\n",
    "::: gsidebar\n",
    "Note that measuring the \"cost\" of an OS operation is often problematic.\n",
    "In a case like this, the operation may complete quickly, but cause other\n",
    "operations to slow down.\n",
    ":::\n",
    "\n",
    "With a 500-entry TLB and a 4-level page table[^4], this results in\n",
    "throwing away 2000 memory accesses worth of work on each context switch.\n",
    "Another solution is to tag each TLB entry with an identifier (an Address\n",
    "Space ID or ASID) identifying the context in which it is valid, allowing\n",
    "entries from multiple contexts to remain in the TLB at once. A special\n",
    "MMU register specifies the ASID of the current process, and entries\n",
    "tagged with other ASIDs are ignored. If a process is interrupted for a\n",
    "short time, most of its TLB entries will remain cached, while the ASID\n",
    "field will prevent them from being mistakenly used by another\n",
    "process[^5].\n",
    "\n",
    "### Page Table Entries\n",
    "\n",
    "The components of a 32-bit Intel page table entry are shown in\n",
    "[\\[fig:vm:pic17\\]](#fig:vm:pic17){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic17\"}; for more information you may wish to refer to\n",
    "<http://wiki.osdev.org/Paging>.\n",
    "\n",
    "![32-bit Intel page table entry\n",
    "(PTE).](../images/pb-figures/mm/virt-mem-pic17.png){#fig:vm:pic17 width=\"\\\\textwidth\"}\n",
    "\n",
    "### Page Permissions - P, W, and U bits\n",
    "\n",
    "Page tables allow different permissions to be applied to memory at a\n",
    "per-page level of granularity.\n",
    "\n",
    "**P=0/1** - If the present bit is zero, the entry is ignored entirely by\n",
    "the MMU, thus preventing any form of access to the corresponding virtual\n",
    "page.\n",
    "\n",
    "**W = 0/1** - Write permission. If the W bit is zero, then read accesses\n",
    "to this page will be allowed, but any attempt to write will cause a\n",
    "fault. By setting the W bit to zero, pages that should not be modified\n",
    "(i.e., program instructions) can be protected. Since\n",
    "correctly-functioning programs in most languages do not change the code\n",
    "generated by the compiler, any attempt to write to such a page must be a\n",
    "bug, and stopping the program earlier rather than later may reduce the\n",
    "amount of damage caused.\n",
    "\n",
    "**U = 0/1** - User permission. If the U bit is zero, then accesses to\n",
    "this page will fail unless the CPU is running in supervisor mode.\n",
    "Typically the OS kernel will \"live\" in a portion of the same address\n",
    "space as the current process, but will hide its code and data structures\n",
    "from access by user processes by setting U=0 on the OS-only mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55a666-5d7f-40a7-8bdb-ee37cfd573ba",
   "metadata": {},
   "source": [
    "### Page Sharing\n",
    "\n",
    "What happens if a single physical memory page is mapped into two\n",
    "different process address spaces? It works just fine.\n",
    "\n",
    "::: gsidebar\n",
    "A question for the reader - why doesn't sharing read-only pages violate\n",
    "the security principle of preventing access from one process to\n",
    "another's memory space?\n",
    ":::\n",
    "\n",
    "Each process is able to read from the page, and any modifications it\n",
    "makes are visible to the other process, as well. In particular, note\n",
    "that the MMU only sees one page table at a time, and doesn't care how a\n",
    "page is mapped in a page table that might be used at some point in the\n",
    "future. If the two processes are running on different CPU cores, then\n",
    "each core has a separate MMU and will not know or care what translations\n",
    "the other cores are using[^6].\n",
    "\n",
    "![Page sharing between two process address\n",
    "spaces](../images/pb-figures/mm/virt-mem-pic18.png){#fig:vm:pageshare width=\"60%\"}\n",
    "\n",
    "There are two ways in which page sharing can be used:\n",
    "\n",
    "**Information sharing:** Some databases and other large programs use\n",
    "memory segments shared between processes to efficiently pass information\n",
    "between those processes.\n",
    "\n",
    "**Memory saving:** Most processes use the same set of libraries to\n",
    "communicate with the OS, the graphical interface, etc., and these\n",
    "libraries must be mapped into the address space of each process. But\n",
    "most of the memory used by these libraries (program code, strings and\n",
    "other constant data) is read-only, and so a single copy can be safely\n",
    "mapped into the address space of each process using the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a5632-51d0-4abb-8628-ebb69c26e3e3",
   "metadata": {},
   "source": [
    "## Page Size, Address Space Size, and 64 Bits\n",
    "\n",
    "The page size of a processor plays a large role in determining how much\n",
    "address space can be addressed. In particular, assuming that the page\n",
    "table tree is built out of single pages, a 2-level page table can map\n",
    "$N^2$ pages, where N is the number of page table entries that fit in a\n",
    "single page. Thus, if the address space is about 32 bits, so that a page\n",
    "table entry (physical page number plus some extra bits) can fit in 4\n",
    "bytes, the maximum virtual memory that can be mapped with a 2-level page\n",
    "table is:\n",
    "\n",
    "::: description*\n",
    "512 ($2^9$) entries per page = virtual address space of $2^{18}$ pages\n",
    "of $2^{11}$ bytes each = $2^{29}$ bytes (0.5 GB)\n",
    "\n",
    "1024 ($2^{10}$) entries per page = virtual address space of $2^{20}$\n",
    "pages of $2^{12}$ bytes each = $2^{32}$ bytes (4GB)\n",
    "\n",
    "2048 ($2^{11}$) entries per page = virtual address space of $2^{22}$\n",
    "pages of $2^{35}$ bytes each = $2^{35}$ bytes (32GB)\n",
    ":::\n",
    "\n",
    "In other words, 2K pages are too small for a 32-bit virtual address\n",
    "space unless the process moves to a deeper page table, while 8K pages\n",
    "are bigger than necessary. (The SPARC and Alpha CPUs, early 64-bit\n",
    "processors, used 8KB pages.)\n",
    "\n",
    "![4-level page table for 64-bit\n",
    "mode.](../images/pb-figures/mm/virt-mem-pic19.png){#fig:4level}\n",
    "\n",
    "64-bit Intel-compatible CPUs use 4K pages for compatibility, and 8-byte\n",
    "page table entries, because four bytes is too small to hold large\n",
    "physical page numbers. This requires a 4-level page table, as shown in\n",
    "[\\[fig:4level\\]](#fig:4level){reference-type=\"autoref\"\n",
    "reference=\"fig:4level\"}.\n",
    "\n",
    "Since each of the 4 levels maps 9 bits of address, for a total of 36\n",
    "bits mapped, and the offset is 12 bits, the total virtual address space\n",
    "is 48 bits---not the full 64 bits, but still huge (256 TB). Clearly the\n",
    "penalty for TLB misses is higher in this case than for 32-bit mode, as\n",
    "there are four memory accesses to the page table for a single\n",
    "translation instead of two. To support virtual address spaces greater\n",
    "than 256 TB, it will be necessary to go to a deeper page table, or\n",
    "larger pages, or perhaps another organization entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40672540-a04f-4db5-bb44-55c09df63dc5",
   "metadata": {},
   "source": [
    "## Creating a Page Table {#vm:sec:4:6}\n",
    "\n",
    "``` {#ch2:lst:hello float=\"\" label=\"ch2:lst:hello\" caption=\"Simple program described in \\\\autoref{vm:sec:4:6}\" xleftmargin=\"1em\" framexleftmargin=\"1em\"}\n",
    "char hello[] = ``hello world\\n'';\n",
    "void _start(void)\n",
    "{\n",
    "    syscall(4, 1, hello, 12); /* syscall 4 = write(fd,buf,len) */\n",
    "    syscall(1);               /* syscall 1 = exit() */\n",
    "}\n",
    "```\n",
    "\n",
    "To see how a page table is created, we start by examining the virtual\n",
    "memory map of perhaps the simplest possible Linux program, shown in\n",
    "[\\[ch2:lst:hello\\]](#ch2:lst:hello){reference-type=\"autoref\"\n",
    "reference=\"ch2:lst:hello\"}. This program doesn't use any libraries, but\n",
    "rather uses direct system calls to write to standard output (always file\n",
    "descriptor 1 in Unix) and to exit. In Linux, \\_start is the point at\n",
    "which execution of a program begins; normally the \\_start function is\n",
    "part of the standard library, which performs initialization before\n",
    "calling main.\n",
    "\n",
    "When this program runs and its memory map is examined (using the `pmap`\n",
    "command) you see the following:\\\n",
    "\n",
    "``` {xleftmargin=\"1em\" framexleftmargin=\"1em\"}\n",
    "00110000    4K r-x--    [ anon ]      <- file header - used by OS\n",
    "08048000    4K r-x--    /tmp/hello    <- .text segment (code)\n",
    "08049000    4K rwx--    /tmp/hello    <- .data segment\n",
    "bffdf000    128K rwx--  [ stack ]\n",
    "```\n",
    "\n",
    "The address space is constructed of a series of contiguous *segments*,\n",
    "each a multiple of the 4 KB page size (although most are the minimum\n",
    "4 KB here), with different permissions for each. (realistic programs\n",
    "will have many more segments; as an example, the address space for the\n",
    "Nautilus file manager process on my Ubuntu 15.10 system has more than\n",
    "800 segments.) To create a page table for this program, the first step\n",
    "is splitting the page numbers into top and bottom halves (all numbers\n",
    "given in hex or binary), as shown in\n",
    "[\\[lst:vm:split\\]](#lst:vm:split){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:split\"}.\n",
    "\n",
    "``` {#lst:vm:split float=\"\" caption=\"Virtual page numbers from the simple 4-segment program\" label=\"lst:vm:split\"}\n",
    "VPN 00110 = 0000 0000 00 01 0001 0000\n",
    "    top10 = 000  bottom10 = 110\n",
    "VPN 08048 = 0000 1000 00 00 0100 1000\n",
    "top10 = 020  bottom10 = 048\n",
    "VPN 08049 = 0000 1000 00 00 0100 1001\n",
    "top10 = 020  bottom10 = 049\n",
    "VPN BFFDF = 1011 1111 11 11 1101 1111\n",
    "top10 = 2FF  bottom10 = 3DF\n",
    "```\n",
    "\n",
    "The first three segments are one page long; note that the last segment\n",
    "is 32 pages (128 KB), so it uses entries 0x3DF to 0x3FF in the\n",
    "second-level page table.\n",
    "\n",
    "The program needs four physical pages for the table; assume that pages\n",
    "0000, 0001, 0002, and 0003 are used for the table, and pages 00004 and\n",
    "up for data/code pages. The actual page table may be seen in\n",
    "[\\[fig:vm:review2\\]](#fig:vm:review2){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:review2\"}. (note that the choice of physical pages is\n",
    "arbitrary; the page numbers within the page directory and page table\n",
    "entries would of course change if different physical pages were used.)\n",
    "\n",
    "![Page table corresponding to memory map for\n",
    "[\\[ch2:lst:hello\\]](#ch2:lst:hello){reference-type=\"autoref\"\n",
    "reference=\"ch2:lst:hello\"}, also used for review\n",
    "questions.](../images/pb-figures/mm/virt-mem-review2.png){#fig:vm:review2 width=\"80%\"}\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1afc73-178a-4933-adad-89388a6e85dc",
   "metadata": {},
   "source": [
    "## Page Faulting\n",
    "\n",
    "In the previous section you saw how the MMU in a Pentium-like CPU\n",
    "determines whether a memory access will succeed:\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\"}\n",
    "if the top-level entry has P=1\n",
    "   and is(read) or W=1\n",
    "   and is(supervisor) or U=1:\n",
    "\n",
    "   if the 2nd-level entry has P=1\n",
    "      and is(read) or W=1\n",
    "      and is(supervisor) or U=1:\n",
    "\n",
    "        use translated address.\n",
    "```\n",
    "\n",
    "If translation fails at any one of the six possible points above (P, W,\n",
    "or U at each level) then a page fault is generated.\n",
    "\n",
    "### Page Faults\n",
    "\n",
    "A page fault is a special form of exception that has the following two\n",
    "characteristics: first, it is generated when an address translation\n",
    "fails, and second, it occurs in the middle of an instruction, not after\n",
    "it is done, so that the instruction can be continued after fixing the\n",
    "problem which caused the page fault. Typical information that the MMU\n",
    "passes to the page fault handler is:\n",
    "\n",
    "::: compactenum\n",
    "The instruction address when the page fault occurred. (this is the\n",
    "return address pushed on the stack as part of the exception handling\n",
    "process)\n",
    "\n",
    "The address that caused the page fault\n",
    "\n",
    "Whether the access attempt was a read or a write\n",
    "\n",
    "Whether the access was attempted in user or supervisor mode\n",
    ":::\n",
    "\n",
    "After the page fault handler returns, the instruction that caused the\n",
    "fault resumes, and it retries the memory access that caused the fault in\n",
    "the first place.\n",
    "\n",
    "::: gsidebarN\n",
    "15 Many of the examples in this section are illustrated using Linux, as\n",
    "the source code is readily available, but same principles (although not\n",
    "details) hold true for other modern OSes such as Windows, Mac OS X, or\n",
    "Solaris.\n",
    "\n",
    "In addition, keep in mind that the virtual memory map for a process is a\n",
    "software concept, and will almost certainly differ between two unrelated\n",
    "operating systems. In contrast, the page table structure is defined by\n",
    "the CPU itself, and must be used in that form by any operating system\n",
    "running on that CPU.\n",
    ":::\n",
    "\n",
    "A single instruction can cause multiple, different page faults, of which\n",
    "there are two different types:\n",
    "\n",
    "- **Instruction fetch:** A fault can occur when the CPU tries to fetch the\n",
    "instruction at a particular address. If the instruction \\\"straddles\\\" a\n",
    "page boundary (i.e., a 6-byte instruction that starts 2 bytes before the\n",
    "end of a page) then you could (in the worst case) get two page faults\n",
    "while trying to fetch an instruction.\n",
    "\n",
    "::: itemize*\n",
    "**Memory access:** Once the instruction has been fetched and decoded, it\n",
    "may require one or more memory accesses that result in page faults.\n",
    "These memory accesses include those to the stack (e.g., for CALL and RET\n",
    "instructions) in addition to load and store instructions. As before,\n",
    "accessing memory that straddles a page boundary will result in\n",
    "additional faults.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cc480-d217-4817-9645-901e5a7bbcd4",
   "metadata": {},
   "source": [
    "### Handling Page Faults\n",
    "\n",
    "Operating systems use two primary strategies in handling page faults:\n",
    "\n",
    "**Kill the program.** If the access is in fact an error, the default\n",
    "action is to kill the process, so that the page fault handler never\n",
    "returns.[^7]\n",
    "\n",
    "**Resolve the fault.** The OS modifies the page tables to establish a\n",
    "valid mapping for the failing address, and then returns from the page\n",
    "fault handler. The CPU retries the memory access, which should succeed\n",
    "(or at least continue farther) this time.\n",
    "\n",
    "In fact, a single instruction can in the worst case result in quite a\n",
    "large number of page faults:\n",
    "\n",
    "::: itemize*\n",
    "On an Intel or similar CPU, multi-byte instructions and data may cross\n",
    "page boundaries; e.g. reading a 4-byte integer at address 0x1FFE\n",
    "(occupying bytes 0x1FFE, 1FFF, 2000, and 2001) could trigger page faults\n",
    "on both page 0x1000 and 0x2000.\n",
    "\n",
    "Every instruction can fault on instruction fetch; memory instructions\n",
    "like LOAD and STORE can also fault on data access.\n",
    "\n",
    "Finally, remember that the stack is in memory, too, so that CALL, PUSH,\n",
    "POP, and RET can all fault if the operation causes an access to a\n",
    "non-mapped stack address.\n",
    ":::\n",
    "\n",
    "If the page fault handler updates the page table (to point to an\n",
    "appropriately initialized page of memory) and then returns promptly, the\n",
    "whole page fault process is invisible to the user or programmer.\n",
    "\n",
    "The page fault handler for an operating system typically only uses the\n",
    "four responses described above---crash, demand-allocate, demand-page,\n",
    "and copy-on-write. More complex page fault mechanisms are used in\n",
    "hardware virtualization, to support virtual machines; those mechanisms\n",
    "will be described later in this book.\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4f49b-c588-4df0-a1c7-6f5d0d700bc9",
   "metadata": {},
   "source": [
    "### Process Address Space, Revisited\n",
    "\n",
    "How does the OS know how to handle a page fault? By examining its\n",
    "internal memory map for a process. We've talked briefly about process\n",
    "memory maps earlier, but now we will look in more detail at a specific\n",
    "one, from a fairly recent (kernel 2.6 or 3.0) 32-bit Linux system. A\n",
    "more thorough description of the Linux memory layout can be found at\\\n",
    "<http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory>\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic100.png){height=\"9\\\\baselineskip\"}\n",
    "\n",
    "In earlier chapters we saw how simple operating systems may use separate\n",
    "portions of the address space for programs and for the operating system.\n",
    "The same approach is often used in dividing up the virtual address space\n",
    "in more complex operating systems, as seen in the 32-bit Linux memory\n",
    "map in [\\[fig:vm:pic100\\]](#fig:vm:pic100){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic100\"}. In recent Linux versions running on 32-bit\n",
    "Intel-compatible CPUs, the kernel \\\"owns\\\" the top 1GB, from virtual\n",
    "address 0xC0000000 to 0xFFFFFFFF, and all kernel code, data structures,\n",
    "and temporary mappings go in this range.\n",
    "\n",
    "The kernel must be part of every address space, so that when exceptions\n",
    "like system calls and page faults change execution from user mode to\n",
    "supervisor mode, all the kernel code and data needed to execute the\n",
    "system call or page fault handler are already available in the current\n",
    "virtual memory map[^8] This is the primary use for the U bit in the page\n",
    "table---by setting the U bit to zero in any mappings for operating\n",
    "system code and data, user processes are prevented from modifying the OS\n",
    "or viewing protected data.\n",
    "\n",
    "Here is the memory map of a very simple process[^9], as reported in\n",
    "`/proc/<pid>/maps`:\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\"}\n",
    "08048000-08049000 r-xp 00000000 08:03 4072226    /tmp/a.out\n",
    "08049000-0804a000 rw-p 00000000 08:03 4072226    /tmp/a.out\n",
    "0804a000-0804b000 rw-p 00000000 00:00 0          [anon]\n",
    "bffd5000-bfff6000 rw-p 00000000 00:00 0          [stack]\n",
    "```\n",
    "\n",
    "The memory space has four segments:\n",
    "\n",
    "::: description*\n",
    "**08048000** (one page) - read-only, executable, mapped from file\n",
    "*a.out*\n",
    "\n",
    "**08049000** (one page) - read/write, mapped from file *a.out*\n",
    "\n",
    "**0804a000** (one page) - read/write, \"anonymous\"\n",
    "\n",
    "**bffd5000-bfff6000** (33 4KB pages) - read/write, \"stack\"\n",
    ":::\n",
    "\n",
    "Where does this map come from? When the OS creates the new address space\n",
    "in the `exec()` system call, it knows it needs to create a stack, but\n",
    "the rest of the information comes from the executable file itself:\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" mathescape=\"false\"}\n",
    "$ objdump -h a.out\n",
    "a.out:     file format elf32-i386\n",
    "\n",
    "Idx Name          Size      VMA       LMA       File off  Algn\n",
    "\n",
    "  0 .text         00000072  08048094  08048094  00000094  2**2\n",
    "                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n",
    "  1 .rodata       000006bd  08048108  08048108  00000108  2**2\n",
    "                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n",
    "  2 .data         00000030  080497c8  080497c8  000007c8  2**2\n",
    "                  CONTENTS, ALLOC, LOAD, DATA\n",
    "  3 .bss          00001000  08049800  08049800  000007f8  2**5\n",
    "                  ALLOC\n",
    "$\n",
    "```\n",
    "\n",
    "Executable files on Linux are stored in the ELF format (Executable and\n",
    "Linking Format), and include a header that describes the file to the OS;\n",
    "the information above came from this header. Looking at the file, the\n",
    "following sections can be seen:\n",
    "\n",
    "  ----------------------- ---------------------------- ---------------------------------\n",
    "              `0 ... x93` various header information   \n",
    "    `00000094 - 00000107` \".text\"                      program code\n",
    "    `00000108 - 000007c7` \".rodata\"                    read/only data (mostly strings)\n",
    "    `000007c8 - 000007e7` \".data\"'                     initialized writable data\n",
    "                (no data) \".bss\"'                      zero-initialized data\n",
    "  ----------------------- ---------------------------- ---------------------------------\n",
    "\n",
    "The BSS section[^10] corresponds to global variables initialized to\n",
    "zero; since the BSS section is initialized to all zeros, there is no\n",
    "need to store its initial contents in the executable file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0fa102-a0f5-4460-9f39-f98b282b6adc",
   "metadata": {},
   "source": [
    "#### Executable file and process address space\n",
    "\n",
    "Here you can see the relationship between the structure of the\n",
    "executable file and the process address space created by the kernel when\n",
    "it runs this executable. One page (08048xxx) is used for read-only code\n",
    "and data, while two pages (08049xxx and 0804Axxx) are used for writable\n",
    "data.\n",
    "\n",
    "![Relationship of executable file header to memory map\n",
    "structure](../images/pb-figures/mm/virt-mem-pic101.png){#fig:vm:pic101 width=\"100%\"}\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfe945-876b-4eb2-bf0c-559a28e81922",
   "metadata": {},
   "source": [
    "## Page Fault Handling\n",
    "\n",
    "In the Linux kernel, the memory map is represented as a list of\n",
    "`vm_area_struct` objects, each corresponding to a separate segment, and\n",
    "each containing the following information:\n",
    "\n",
    "::: itemize*\n",
    "Start address\n",
    "\n",
    "End+1 address\n",
    "\n",
    "Permissions: read/write/execute\n",
    "\n",
    "Flags: various details on how to handle this segment\n",
    "\n",
    "File, offset (if mapped from a file)\n",
    ":::\n",
    "\n",
    "Unlike the page table, which is a simple structure defined by the CPU\n",
    "hardware, the virtual memory map in the OS is a purely software data\n",
    "structure, and can be as simple or complex as the OS writers decide.\n",
    "\n",
    "With the map from\n",
    "[\\[fig:vm:pic101\\]](#fig:vm:pic101){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic101\"}, the possibilities when the page fault\n",
    "handler looks up a faulting address are:\n",
    "\n",
    "::: itemize*\n",
    "No match: This is an access to an undefined address. It's a bug, and the\n",
    "OS terminates the process with a \\\"segmentation fault\\\" error.\n",
    "\n",
    "Any page in bff08000-bff29000: These are demand-allocate stack pages.\n",
    "The page fault handler allocates a physical memory page, zeros it (for\n",
    "safety), puts it into the page table, and returns.\n",
    "\n",
    "Page 08048000: This page is mapped read-only from the executable file\n",
    "'a.out,' so the page fault handler allocates a page, reads the first 4KB\n",
    "from 'a.out' into it, inserts it into the page table (marked read-only),\n",
    "and returns.\n",
    "\n",
    "Page 08049000: This page is mapped read/write from the executable file.\n",
    "Just like page 08048000, the page fault handler allocates a page, reads\n",
    "its contents from the executable, maps the page in the page table\n",
    "(read/write this time) and returns.\n",
    "\n",
    "Page 0804a000: Like the stack, this is demand-allocated and zero-filled,\n",
    "and is handled the same way.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db6566-bfdd-4728-8262-da605e142afc",
   "metadata": {},
   "source": [
    "### Page Faults in the Kernel\n",
    "\n",
    "::: gsidebarN\n",
    "9 Although common in the past, modern Windows and Linux systems rarely\n",
    "seem to crash due to driver problems. (Although my Mac panics every\n",
    "month or two.) If you ever develop kernel drivers, however, you will\n",
    "become very familiar with them.\n",
    ":::\n",
    "\n",
    "What happens if there is a page fault while the CPU is running kernel\n",
    "code in supervisor mode? It depends.\n",
    "\n",
    "If the error is due to a bug in kernel-mode code, then in most operating\n",
    "systems the kernel is unable to handle it. In Linux the system will\n",
    "display an \"Oops\" message, as shown in\n",
    "[\\[lst:vm:oops\\]](#lst:vm:oops){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:oops\"}, while in Windows the result is typically a\n",
    "\"kernel panic\", which used to be called a Blue Screen of Death. Most of\n",
    "the time in Linux the process executing when this happens will be\n",
    "terminated, but the rest of the system remains running with possibly\n",
    "reduced functionality.\n",
    "\n",
    "``` {#lst:vm:oops float=\"\" basicstyle=\"\\\\ttfamily\\\\scriptsize\" mathescape=\"false\" label=\"lst:vm:oops\" caption=\"Linux kernel ``Oops'' message due to NULL pointer dereference.\" xleftmargin=\"0pt\" framexleftmargin=\"0pt\"}\n",
    "[  397.864759] BUG: unable to handle kernel NULL pointer dereference at \n",
    "                                                                0000000000000004\n",
    "[  397.865725] IP: [<ffffffffc01d1027>] track2lba+0x27/0x3f [dm_vguard]\n",
    "[  397.866619] PGD 0 \n",
    "[  397.866929] Oops: 0000 [#1] SMP \n",
    "[  397.867395] Modules linked in: [...]\n",
    "[  397.872730] CPU: 0 PID: 1335 Comm: dmsetup Tainted: G           OE   4.6.0 #3\n",
    "[  397.873419] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS ...\n",
    "[  397.874487] task: ffff88003cd10e40 ti: ffff880037080000 task.ti: ffff88003708\n",
    "[  397.875375] RIP: 0010:[<ffffffffc01d1027>]  [<ffffffffc01d1027>] track2lba+0x27\n",
    "[  397.876509] RSP: 0018:ffff880037083bd0  EFLAGS: 00010282\n",
    "[  397.877193] RAX: 0000000000000001 RBX: 0000000000003520 RCX: 0000000000000000\n",
    "[  397.878085] RDX: 0000000000000000 RSI: 0000000000003520 RDI: ffff880036bd70c0\n",
    "[  397.879016] RBP: ffff880037083bd0 R08: 00000000000001b0 R09: 0000000000000000\n",
    "[  397.879912] R10: 000000000000000a R11: f000000000000000 R12: ffff880036bd70c0\n",
    "[  397.880763] R13: 00000000002e46e0 R14: ffffc900001f7040 R15: 0000000000000000\n",
    "[  397.881618] FS:  00007f5767938700(0000) GS:ffff88003fc00000(0000) \n",
    "[  397.915186] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n",
    "[  397.932122] CR2: 0000000000000004 CR3: 000000003d3ea000 CR4: 00000000000406f0\n",
    "[  397.949459] Stack:\n",
    "                      ... stack contents and backtrace omitted ...\n",
    "```\n",
    "\n",
    "But what about addresses passed by the user in a system call? For\n",
    "example, what if the memory address passed to a [read](read){.uri}\n",
    "system call has been paged out, or not instantiated yet? It turns out\n",
    "that the same page faulting logic can be used in the kernel, as\n",
    "well---the first access to an unmapped page will result in a fault, the\n",
    "process will be interrupted (in the kernel this time, rather than in\n",
    "user-space code), and then execution will resume after the page fault is\n",
    "handled.\n",
    "\n",
    "But what if the user passes a bad address? We can't just kill the\n",
    "process partway through the system call, because that would risk leaving\n",
    "internal operating system data structures in an inconsistent state. (Not\n",
    "only that, but the POSIX standard requires that system calls return the\n",
    "EFAULT error in response to bad addresses, not exit.) Instead, all code\n",
    "in the Linux kernel which accesses user-provided memory addresses is\n",
    "supposed to use a pair of functions,\n",
    "[copy_from_user](copy_from_user){.uri} and\n",
    "[copy_to_user](copy_to_user){.uri}, which check that the user-provided\n",
    "memory region is valid for user-mode access[^11].\n",
    "\n",
    "In very early versions of Linux the kernel ran in a separate address\n",
    "space where virtual addresses mapped directly to physical addresses, and\n",
    "so these functions actually interpreted the page tables to translate\n",
    "virtual addresses to physical (i.e. kernel virtual) addresses, which was\n",
    "slow but made it easy to return an error if an address was bad. Newer\n",
    "Linux versions map the kernel and its data structures into each process\n",
    "virtual address space, making these functions much faster but more\n",
    "complicated. The speedup is because there is no longer any need to\n",
    "translate page tables in software; instead the two\n",
    "[copy\\_\\*\\_user](copy_*_user){.uri} functions just perform a few checks\n",
    "and then a [memcpy](memcpy){.uri}. More complicated because if it fails\n",
    "we don't find out about it in either of these functions, but rather in\n",
    "the page fault handler itself. To make this work, if the page fault (a)\n",
    "occurs in kernel mode, and (b) the handler can't find a translation for\n",
    "the address, it checks to see if the fault occurred while executing the\n",
    "[copy_from_user](copy_from_user){.uri} or\n",
    "[copy_to_user](copy_to_user){.uri} functions, and if so it performs some\n",
    "horrible stack manipulation to cause that function to return an error\n",
    "code[^12].\n",
    "\n",
    "But what if a page fault occurs in the kernel outside of these two\n",
    "functions? That should never happen, because kernel structures are\n",
    "allocated from memory that's already mapped in the kernel address space.\n",
    "In other words it's a bug, just like the bugs that cause segmentation\n",
    "faults in your C programs. And just like those bugs it causes a crash,\n",
    "resulting in an error message such as the one shown in\n",
    "[\\[lst:vm:oops\\]](#lst:vm:oops){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:oops\"}. If the kernel was running in a process context\n",
    "(e.g. executing system call code) then the currently-running process\n",
    "will be killed, while if this occurs during an interrupt the system will\n",
    "crash. The equivalent in Windows is called a Blue Screen of Death\n",
    "(although they changed the color several versions back); since almost\n",
    "all Windows kernel code executes in interrupt context, these errors\n",
    "always result in a system crash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe5c2d-d301-4f3a-9a73-d90c886ecae1",
   "metadata": {},
   "source": [
    "## Shared Executables and Libraries\n",
    "\n",
    "In addition to simplifying memory allocation, virtual memory can also\n",
    "allow memory to be used more efficiently when running multiple\n",
    "processes.\n",
    "\n",
    "Consider the case of a multi-user computer, where multiple users are\n",
    "running the same program (i.e., the shell, [/bin/bash](/bin/bash){.uri})\n",
    "at the same time. If we just follow the rules we've seen above for\n",
    "allocating and filling memory, the memory usage of the three programs\n",
    "will look something like the left-hand side of\n",
    "[\\[fig:vm:pic113\\]](#fig:vm:pic113){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic113\"}.\n",
    "\n",
    "![Memory usage of three copies of the same\n",
    "program.](../images/pb-figures/mm/virt-mem-pic113.png){#fig:vm:pic113\n",
    "width=\"\\\\textwidth\"}\n",
    "\n",
    "\\(a\\) without memory sharing (b) with memory sharing\n",
    "\n",
    "However since the code section of each process is identical, we can\n",
    "share those pages, giving the picture on the right-hand side of\n",
    "[\\[fig:vm:pic113\\]](#fig:vm:pic113){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic113\"}. [^13]\n",
    "\n",
    "How does the OS determine that it can share the same page between two\n",
    "processes? When a page fault happens, and the page fault handler\n",
    "determines that it needs to read (i.e., page 10 from the executable\n",
    "[/bin/bash](/bin/bash){.uri}) it first searches to see whether that page\n",
    "is already stored in some existing memory page[^14]. If so, it can\n",
    "increment a reference count on that page and map it into the process\n",
    "page table, instead of having to allocate a new page and read the data\n",
    "in from the disk. When a process exits, instead of blindly de-allocating\n",
    "any memory mapped by that process, the reference count of each page is\n",
    "decremented, and it is only freed when this count goes to zero,\n",
    "indicating that no other address spaces are mapping that page.\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic103.png){width=\"\\\\textwidth\"}\\\n",
    "\n",
    "![Address mismatch when lib1 and lib2 are linked with different\n",
    "programs](../images/pb-figures/mm/virt-mem-pic104.png){#fig:vm:pic103\n",
    "width=\"\\\\textwidth\"}\n",
    "\n",
    "Note that the operating system also provides a way for applications to\n",
    "create memory regions which are explicitly shared between processes, and\n",
    "used for communication between them. This can be used for\n",
    "high-performance communication between processes, and is used in at\n",
    "least one program that people actually use.\n",
    "\n",
    "Sharing memory at the program level worked well on multi-user systems,\n",
    "as you just saw, where many people ran the same simple programs (e.g.,\n",
    "the shell, editor, and compiler) at the same time. With the advent of\n",
    "graphical interfaces and single-user workstations, it stopped working so\n",
    "well. Instead, now there's a single user running one copy each of\n",
    "several different programs. Worse yet, each program is far more\n",
    "complicated than in the past, as the libraries for interacting with the\n",
    "display, mouse, and keyboard are inevitably larger and more complex than\n",
    "the simple libraries needed to define functions like `printf` for\n",
    "terminal output.[^15]\n",
    "\n",
    "The problem here is that even though your browser, text editor, and\n",
    "email program all use the same libraries, each program ends up being a\n",
    "unique combination of code, combining the actual program code with a\n",
    "specific set of libraries, as seen in\n",
    "[\\[fig:vm:pic103\\]](#fig:vm:pic103){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic103\"}. So even if the operating system *tried* to\n",
    "recognize identical regions in the two files, the differing alignment\n",
    "would make it impossible to share pages between them.\n",
    "\n",
    "\n",
    "![image](../images/pb-figures/mm/virt-mem-pic105.png){height=\"8\\\\baselineskip\"}\n",
    "\n",
    "\n",
    "*Shared libraries* eliminate this wasted space by combining code and\n",
    "libraries in a way that allows sharing in most cases. To do this, the\n",
    "program and the libraries are structured so that different programs can\n",
    "share a single copy of the same library. In simple terms, each library\n",
    "is made to look like a separate program, which means that multiple\n",
    "copies of the same library can be shared, even if the different programs\n",
    "that use it can't be shared.\n",
    "\n",
    "In [\\[fig:vm:pic105\\]](#fig:vm:pic105){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic105\"} we see how each shared library is given its\n",
    "own region of address space, rather than packing them all into a single\n",
    "segment. The base programs (program1 and program2 below) still differ,\n",
    "but the libraries remain identical and can be shared between address\n",
    "spaces.\n",
    "\n",
    "``` {#lst:vm:hello2 float=\"t\" caption=\"Traditional ``hello world'' program \\\\vspace{-\\\\baselineskip}\" label=\"lst:vm:hello2\" basicstyle=\"\\\\ttfamily\\\\footnotesize\"}\n",
    "#include <stdio.h>\n",
    "int main() \n",
    "{ \n",
    "    printf(\"hello world\\n\");\n",
    "}\n",
    "```\n",
    "\n",
    "``` {#lst:vm:ldd float=\"t\" xleftmargin=\"12pt\" framexleftmargin=\"12pt\" basicstyle=\"\\\\ttfamily\\\\scriptsize\" mathescape=\"false\" caption=\"Libraries linked with program in \\\\autoref{lst:vm:hello2}. \\\\vspace{-\\\\baselineskip}\" label=\"lst:vm:ldd\"}\n",
    "pjd@pjd-fx:/tmp$ ldd a.out\n",
    "    linux-vdso.so.1 =>  (0x00007fff99d56000)\n",
    "    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5a0bb94000)\n",
    "    /lib64/ld-linux-x86-64.so.2 (0x00005590e6bba000)\n",
    "```\n",
    "\n",
    "This approach is taken in Linux; if we compile the standard \"hello\n",
    "world\" program shown in\n",
    "[\\[lst:vm:hello2\\]](#lst:vm:hello2){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:hello2\"} we can use the `ldd` command to list the\n",
    "libraries which will be loaded at runtime, as seen in\n",
    "[\\[lst:vm:ldd\\]](#lst:vm:ldd){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:ldd\"}, resulting in the memory map in\n",
    "[\\[lst:vm:map:hello2\\]](#lst:vm:map:hello2){reference-type=\"autoref\"\n",
    "reference=\"lst:vm:map:hello2\"}.\n",
    "\n",
    "``` {#lst:vm:map:hello2 float=\"b\" mathescape=\"false\" caption=\"Memory map for hello world program in \\\\autoref{lst:vm:hello2}\" label=\"lst:vm:map:hello2\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" xleftmargin=\"12pt\" framexleftmargin=\"12pt\"}\n",
    "pjd@pjd-fx:~$ pmap -p 18012\n",
    "0000000000400000      4K r-x-- /tmp/a.out\n",
    "0000000000600000      4K r---- /tmp/a.out\n",
    "0000000000601000      4K rw--- /tmp/a.out\n",
    "00007ffff7a0f000   1792K r-x-- /lib/x86_64-linux-gnu/libc-2.21.so\n",
    "00007ffff7bcf000   2048K ----- /lib/x86_64-linux-gnu/libc-2.21.so\n",
    "00007ffff7dcf000     16K r---- /lib/x86_64-linux-gnu/libc-2.21.so\n",
    "00007ffff7dd3000      8K rw--- /lib/x86_64-linux-gnu/libc-2.21.so\n",
    "00007ffff7dd5000     16K rw---   [ anon ]\n",
    "00007ffff7dd9000    144K r-x-- /lib/x86_64-linux-gnu/ld-2.21.so\n",
    "00007ffff7fcd000     12K rw---   [ anon ]\n",
    "00007ffff7ff6000      8K rw---   [ anon ]\n",
    "00007ffff7ff8000      8K r----   [ anon ]\n",
    "00007ffff7ffa000      8K r-x--   [ anon ]\n",
    "00007ffff7ffc000      4K r---- /lib/x86_64-linux-gnu/ld-2.21.so\n",
    "00007ffff7ffd000      4K rw--- /lib/x86_64-linux-gnu/ld-2.21.so\n",
    "00007ffff7ffe000      4K rw---   [ anon ]\n",
    "00007ffffffde000    132K rw---   [ stack ]\n",
    "ffffffffff600000      4K r-x--   [ anon ]\n",
    " total             4220K\n",
    "```\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560089c-b9fb-4fe2-b8a6-3eda0e76910d",
   "metadata": {},
   "source": [
    "### More Memory Sharing: `fork()` and copy-on-write\n",
    "\n",
    "In all the cases you've seen so far, page sharing has been used to share\n",
    "read-only pages---these are intrinsically safe to share, because\n",
    "processes are unable to modify the pages and thereby affect other\n",
    "processes. But, can writable pages be shared safely? The answer is yes,\n",
    "but it has to be done carefully.\n",
    "\n",
    "First, some background on why this is important. The Unix operating\n",
    "system uses two system calls to create new processes and execute\n",
    "programs: `fork()` and `exec()`. `fork()` makes a copy of the current\n",
    "process[^16], while `exec(file)` replaces the address space of the\n",
    "current process with the program defined by `file` and begins executing\n",
    "that program at its designated starting point.\n",
    "\n",
    "UNIX uses this method because of an arbitrary choice someone made 40\n",
    "years ago; there are many other ways to do it, each of them with their\n",
    "own problems. However this is how UNIX works, and we're stuck with it,\n",
    "so it's important to be able to do it quickly.\n",
    "\n",
    "In early versions of Unix, `fork()` was implemented by literally copying\n",
    "all the writable sections (e.g., stack, data) of the parent process\n",
    "address space into the child process address space. After doing all this\n",
    "work, most (but not all) of the time, the first thing the child process\n",
    "would do is to call exec(), throwing away the entire contents of the\n",
    "address space that were just copied. It's bad enough when the shell does\n",
    "this, but even worse when a large program (e.g. Chrome) tries to execute\n",
    "a small program (e.g. /bin/ls) in a child process.\n",
    "\n",
    "We've already seen how to share read-only data, but can we do anything\n",
    "about writable data? In particular, data which is writable, but isn't\n",
    "actually going to be written?\n",
    "\n",
    "A quick inspection of several Firefox and Safari instances (using pmap\n",
    "on Linux and vmmap on OS X) indicates that a browser with two or three\n",
    "open tabs can easily have over 300MB of writable address space[^17].\n",
    "When fork is executed these writable pages can't just be given writable\n",
    "mappings in the child process, or changes made in one process would be\n",
    "visible in the other. In certain cases (i.e., the stack) this mutual\n",
    "over-writing of memory would almost certainly be disastrous.\n",
    "\n",
    "However in practice, most of these writable pages *won't* be written to\n",
    "again. In fact, if the child process only executes a few lines of code\n",
    "and then calls [exec](exec){.uri}, it may only modify a handful of pages\n",
    "before its virtual address space is destroyed and replaced with a new\n",
    "one.\n",
    "\n",
    "::: gsidebarN\n",
    "12 Copy-on-write is in fact a widely-used strategy in computer systems.\n",
    "It is effectively a \"lazy\" copy, doing only the minimal amount of work\n",
    "needed and reducing both the cost of copying and the total space\n",
    "consumed. Similar copy-on-write mechanisms can be seen in file systems,\n",
    "storage devices, and some programming language runtime systems.\n",
    ":::\n",
    "\n",
    "Linux uses a technique called *copy-on-write* to eliminate the need to\n",
    "copy most of this memory. When a child process is created in the\n",
    "[fork](fork){.uri} system call, its address space shares not only the\n",
    "read-only pages from the parent process, but the writable pages as well.\n",
    "To prevent the two processes from interfering with each other, these\n",
    "pages are mapped read-only, resulting in a page fault whenever they are\n",
    "accessed by either process, but flagged as copy-on-write in the kernel\n",
    "memory map structures. This results in a page fault when either process\n",
    "tries to write to one of these pages; the page fault handler then\n",
    "\"breaks\" the sharing for that page, by allocating a new page, copying\n",
    "the old one, and mapping a separate page read-write in each of the\n",
    "processes.\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a738029-8d8a-425c-b84c-f6c627097c73",
   "metadata": {},
   "source": [
    "### Memory Over-Commitment and Paging\n",
    "\n",
    "Page faults allow data to be dynamically fetched into memory when it is\n",
    "needed, in the same way that the CPU dynamically fetches data from\n",
    "memory into the cache. This allows the operating system to over-commit\n",
    "memory: the sum of all process address spaces can add up to more memory\n",
    "than is available, although the total amount of memory mapped at any\n",
    "point in time must fit into RAM. This means that when a page fault\n",
    "occurs and a page is allocated to a process, another page (from that or\n",
    "another process) may need to be evicted from memory.\n",
    "\n",
    "::: gsidebarN\n",
    "12 **Types of Virtual Segments**: There are two types of virtual\n",
    "segments: file-backed and anonymous. File-backed segments are what the\n",
    "name says; approximately 99.9% of them are read-only mappings of\n",
    "demand-paged executables. Anonymous mappings are called this because\n",
    "they don't correspond to a file; most of them contain writable program\n",
    "data or stacks.\n",
    ":::\n",
    "\n",
    "Evicting a read-only page mapped from a file is simple: just forget the\n",
    "mapping and free the page; if a fault for that page occurs later, the\n",
    "page can be read back from disk. Occasionally pages are mapped\n",
    "read/write from a file, when a program explicitly requests it with\n",
    "`mmap`---in that case the OS can write any modified data back to the\n",
    "file and then evict the page; again it can be paged back from disk if\n",
    "needed again.\n",
    "\n",
    "Anonymous segments such as stack and heap are typically created in\n",
    "memory and do not need to be swapped; however if the system runs low on\n",
    "memory it may evict anonymous pages owned by idle processes, in order to\n",
    "give more memory to the currently-running ones. To do this the OS\n",
    "allocates a location in \"swap space\" on disk: typically a dedicated swap\n",
    "partition in Linux, and the `PAGEFILE.sys` and `/var/vm/swapfile` files\n",
    "in Windows and OSX respectively. The data must first be written out to\n",
    "that location, then the OS can store the page-to-location mapping and\n",
    "release the memory page.\n",
    "\n",
    "![Page Table Entry with D (dirty)\n",
    "bit](../images/pb-figures/mm/virt-mem-pic106.png){#fig:vm:pic106 width=\"\\\\textwidth\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713f08b-895d-4741-b1d2-a86457bee519",
   "metadata": {},
   "source": [
    "### Dirty and Clean Pages\n",
    "\n",
    "How does the operating system determine whether a page has been modified\n",
    "and needs to be written to disk? It uses the D bit in the page table\n",
    "entry for this, as seen in\n",
    "[\\[fig:vm:pic106\\]](#fig:vm:pic106){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic106\"}. When a page is mapped in the page table, the\n",
    "D bit in the PTE is set to zero; when the CPU writes to a page with D =\n",
    "0, the MMU re-writes the page table entry with D = 1. When the OS\n",
    "decides to evict a page, the D bit tells it whether the page is \"clean,\"\n",
    "i.e., it hasn't been modified, or whether it is \"dirty\" and has to be\n",
    "written back to disk.\n",
    "\n",
    "When the OS is paging in from a file (e.g. executable code), it is\n",
    "straightforward to find the data to read in, as there is a direct\n",
    "mapping between a range of pages in a specific file and corresponding\n",
    "pages in the virtual memory space. This correspondence can easily be\n",
    "stored in the definition of that virtual address segment. When pages are\n",
    "saved to swap space this doesn't work, however, as the locations they\n",
    "are saved to are allocated dynamically and fairly arbitrarily.\n",
    "\n",
    "This problem is solved by using the page table itself. After evicting a\n",
    "page, its page table entry is invalidated by setting P = 0; however, the\n",
    "other 31 bits of the entry are ignored by the MMU. These bits are used\n",
    "to store the location of the page in swap space, so it can be found\n",
    "later later at page fault time. Thus, the page table entry does dual\n",
    "duty: when the page is present it points to the physical page itself,\n",
    "and is interpreted by the MMU; otherwise, it points to a location in\n",
    "swap space, and is ignored by the MMU and used by the software page\n",
    "fault handler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b882322-e44e-4060-8de7-b6a894581627",
   "metadata": {},
   "source": [
    "### The Memory Hierarchy\n",
    "\n",
    "Demand paging from files and from swap provides the mechanisms to create\n",
    "the traditional memory hierarchy, as shown in\n",
    "[\\[fig:vm:pic107\\]](#fig:vm:pic107){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic107\"}.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "![Memory Hierarchy](../images/pb-figures/mm/virt-mem-pic108.png){#fig:vm:pic108\n",
    "width=\"60%\"}\n",
    "\n",
    "To access address A:\n",
    "\n",
    "::: itemize*\n",
    "If it's not in the cache, then the old cache line is evicted, and A is\n",
    "loaded into the resulting empty cache line. This is done in hardware.\n",
    "\n",
    "If it's not in memory, then the old page is evicted, and the page\n",
    "containing A is loaded into the resulting empty page. This is done in\n",
    "software.\n",
    ":::\n",
    "\n",
    "In general, this works because of *locality*: when a cache line is\n",
    "brought in from memory, a page is loaded into in memory from disk, etc.,\n",
    "it tends to get accessed multiple times before eviction.\n",
    "\n",
    "Decades ago this was used to run programs much bigger than physical\n",
    "memory---CPUs were slow and disks were almost as fast as they are today,\n",
    "so the relative overhead of paging infrequently-used data to disk was\n",
    "low. Today's CPUs are thousands of times faster, while disks are only a\n",
    "few times faster, and virtual memory doesn't seem like such a great idea\n",
    "anymore. However it still gets used, even on desktop and laptop systems,\n",
    "to \"steal\" memory from idle programs: if you leave a large program like\n",
    "Chrome or Microsoft Word idle for half an hour while you use another\n",
    "memory-hungry program, memory will be released from the idle process and\n",
    "given to the active one; if you switch back, the original program will\n",
    "run slowly for a while as it swaps these pages back in.\n",
    "\n",
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f8a27-a7c2-4ead-b242-550aa789cf73",
   "metadata": {},
   "source": [
    "## Page Replacement\n",
    "\n",
    "If there's a limited amount of memory available, then every time a page\n",
    "is swapped in from disk, it will be necessary to remove, or evict,\n",
    "another page from memory. The choice of which page to evict is\n",
    "important: the best page to choose would be one that won't be needed\n",
    "anymore, while the worst page to evict would be one of the next to be\n",
    "used. (in that case, paging it back in would force another page to be\n",
    "evicted, and the work of paging it out and back in again would be\n",
    "wasted.) In fact, replacement of items in a cache is a general problem\n",
    "in computer systems; examples include:\n",
    "\n",
    "::: itemize*\n",
    "Cache line replacement in the hardware CPU cache\n",
    "\n",
    "Entry replacement in the TLB\n",
    "\n",
    "Buffer replacement in a file system buffer pool\n",
    "\n",
    "Page replacement in virtual memory\n",
    ":::\n",
    "\n",
    "The page replacement problem can be stated in abstract form:\n",
    "\n",
    "Given the following:\n",
    "\n",
    "::: compactenum\n",
    "A disk holding $d$ (virtual) pages, with virtual addresses\n",
    "$0,\\ldots d-1$;\n",
    "\n",
    "A memory ${M}$ consisting of $m$ (physical) pages, where each page is\n",
    "either empty or holds one of the $d$ virtual pages, and\n",
    "\n",
    "An access pattern $a_1, a_2, a_3, \\cdots$ where each $a_i$ is a virtual\n",
    "address in the range $(0,d-1)$:\n",
    ":::\n",
    "\n",
    "a demand-paging strategy is an algorithm which for each access $a_i$\n",
    "does the following:\n",
    "\n",
    "::: compactitem\n",
    "If $a_i$ is already in one of the $m$ physical pages in ${M}$ (i.e. a\n",
    "*hit*): do nothing\n",
    "\n",
    "Otherwise (a miss) it must:\n",
    "\n",
    "Select a physical page $j$ in ${M}$ (holding some virtual address $M_j$)\n",
    "and evict it, then\n",
    "\n",
    "Fetch virtual page $a_i$ from disk into physical page $j$\n",
    ":::\n",
    "\n",
    "In other words it only fetches page $j$ *on demand*---i.e. in response\n",
    "to a request for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145f834-c66b-4d0d-b978-9544b5eeac35",
   "metadata": {},
   "source": [
    "## Page Replacement Strategies\n",
    "\n",
    "In this class we consider the following page replacement strategies:\n",
    "\n",
    "::: itemize*\n",
    "FIFO: *first-in first-out*. The page evicted from memory is the first\n",
    "page to have been fetched into memory.\n",
    "\n",
    "LRU: *least-recently used*. Here, accesses to each page are tracked\n",
    "after it has been loaded into memory, and the least-recently-used page\n",
    "is evicted (unsurprisingly, given the name of the strategy).\n",
    "\n",
    "OPT: this is the optimal demand-paged strategy, which is simple but\n",
    "impossible to implement, since it requires knowledge of the future. It's\n",
    "examined because it provides a way of telling how well a real\n",
    "replacement strategy is performing---is it close to OPT, or is it far\n",
    "worse?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4717c7b-c63b-4cef-a976-3f7059b750f6",
   "metadata": {},
   "source": [
    "### FIFO\n",
    "\n",
    "![FIFO cleaning](../images/pb-figures/mm/virt-mem-pic107.png){#fig:vm:pic107 width=\"100%\"}\n",
    "\n",
    "This strategy is very simple to implement, as it only requires keeping\n",
    "track of the order in which pages were fetched into memory. Given 4\n",
    "pages in physical memory, and the following access pattern:\n",
    "\n",
    "1 2 3 4 2 1 3 4 5 4 1 2 5 6 3 2 5 2 3 6\n",
    "\n",
    "The contents of memory after each access is shown in\n",
    "[\\[fig:vm:pic107\\]](#fig:vm:pic107){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic107\"}, with hits shown in light grey and pages\n",
    "evicted (when misses occur) shown in dark grey.\n",
    "\n",
    "![LRU cleaning](../images/pb-figures/mm/virt-mem-pic109.png){#fig:vm:pic109 width=\"100%\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c08de7-52d6-4d5b-a185-4e0375fec4b6",
   "metadata": {},
   "source": [
    "### LRU\n",
    "\n",
    "The idea behind LRU is that pages which have been accessed in the recent\n",
    "past are likely to be accessed in the near future, and pages which\n",
    "haven't, aren't. LRU replacement is shown in\n",
    "[\\[fig:vm:pic109\\]](#fig:vm:pic109){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic109\"}.\n",
    "\n",
    "To make the operation of the LRU algorithm more clear, on each hit, the\n",
    "accessed page is moved to the top of the column. (This is how LRU is\n",
    "typically implemented in software: elements are kept in a list, and on\n",
    "access, an element is removed and reinserted at the front of the list.\n",
    "The least-recently-used element may then be found by taking the tail of\n",
    "the list) Although this is a small example, a performance improvement is\n",
    "noted, with four misses compared to six for FIFO.\n",
    "\n",
    "![optimal cleaning](../images/pb-figures/mm/virt-mem-pic110.png){#fig:vm:pic110\n",
    "width=\"100%\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf93a02-3059-4206-82da-b1bfae5cec98",
   "metadata": {},
   "source": [
    "### OPT\n",
    "\n",
    "The optimal algorithm picks a page to evict by looking forward in time\n",
    "and finding the page which goes for the longest time without being\n",
    "accessed again. Except for seeing the future, OPT plays by the same\n",
    "rules as other demand-paging algorithms: in particular, it can't fetch a\n",
    "page until it is accessed. (That's why the OPT strategy still has\n",
    "misses.) OPT is shown in\n",
    "[\\[fig:vm:pic110\\]](#fig:vm:pic110){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic110\"}, using the same access pattern as before. The\n",
    "first eviction decision is shown graphically: pages 4, 2, and 1 are\n",
    "accessed 1, 3, and 2 steps in the future, respectively, while page 3\n",
    "isn't accessed for 6 steps and is thus chosen to be evicted.\n",
    "\n",
    "\\\n",
    "![image](../images/pb-figures/mm/virt-mem-pic111.png){width=\"\\\\textwidth\"}\n",
    "\n",
    "![CLOCK Algorithm](../images/pb-figures/mm/virt-mem-pic112.png){#fig:vm:pic112\n",
    "width=\"\\\\textwidth\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3cc8b-ad8e-4043-a0a5-cf0a3042b9bd",
   "metadata": {},
   "source": [
    "### FIFO with Second Chance (CLOCK)\n",
    "\n",
    "LRU is simple and quite effective in many caching applications, and it's\n",
    "ideal that the operating system uses it to determine which pages to\n",
    "evict from memory. But there is one small problem in using it in a\n",
    "virtual memory system: in this case, a \"miss\" corresponds to a page\n",
    "fault and fetching a page from disk, while a \"hit\" is when the page is\n",
    "already mapped in memory and the access succeeds in hardware. This means\n",
    "that once a page is faulted into memory, any further use of that page is\n",
    "\"invisible\" to the operating system. If the OS doesn't know when a page\n",
    "was last used, it can't implement the Least-Recently-Used replacement\n",
    "strategy.\n",
    "\n",
    "Despite this issue, it's still possible to do better than FIFO by using\n",
    "the A (\"accessed\") bit in the page table entry, which indicates whether\n",
    "the page has been accessed since the last time the bit was cleared[^18].\n",
    "In [\\[fig:vm:pic111\\]](#fig:vm:pic111){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic111\"} we see an algorithm called \"FIFO with second\n",
    "chance,\" where the A bit is used to determine whether a page has been\n",
    "accessed while it was in the FIFO queue. If the A bit is 1, the\n",
    "replacement algorithm clears it and re-writes the page table entry, and\n",
    "the page is given \"another chance,\" i.e., it is cycled back to the head\n",
    "of the list. If the A bit is 0, then there have been no accesses to the\n",
    "page during its entire trip through the list, and so it is selected for\n",
    "replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ea960-547e-4882-955f-04ee542dfdcb",
   "metadata": {},
   "source": [
    "### CLOCK\n",
    "\n",
    "An alternate way of visualizing the FIFO with second chance algorithm is\n",
    "shown in [\\[fig:vm:pic112\\]](#fig:vm:pic112){reference-type=\"autoref\"\n",
    "reference=\"fig:vm:pic112\"}. Pages are arranged in a circle, with a\n",
    "\"hand\" advancing around the circle testing pages and determining whether\n",
    "to keep or evict them. This description is the origin of the widely-used\n",
    "name for this algorithm, CLOCK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89259f73-0deb-4d37-8232-5d808a5ce30b",
   "metadata": {},
   "source": [
    "#### Review questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30f92d-8bcb-4a94-9db8-c03b57ec1489",
   "metadata": {},
   "source": [
    "### Answers to Review questions\n",
    "\n",
    "::: compactenum\n",
    "in virtmem:2,virtmem:3,virtmem:4,virtmem:5,\n",
    "virtmem:6,virtmem:7,virtmem:8a,virtmem:8b\n",
    ":::\n",
    "\n",
    "[^1]: Not even on Intel CPUs, which support base+bounds translation\n",
    "    using *segment registers*. Nearly every operating system running on\n",
    "    these CPUs sets base=0 and bound=max as one of the very first steps\n",
    "    in hardware initialization.\n",
    "\n",
    "[^2]: This is similar to *garbage collection* in Java and other\n",
    "    languages; however in that case pointers to the garbage-collected\n",
    "    memory must be changed to point to the new locations.\n",
    "\n",
    "[^3]: Besides, the hardware designers would rather check the value of a\n",
    "    single wire than compare a whole bunch of bits at once.\n",
    "\n",
    "[^4]: Both values typical of 64-bit desktop CPUs.\n",
    "\n",
    "[^5]: ASIDs are supported in most modern x86 processors as part of\n",
    "    hardware virtualization extensions, which are discussed (in not very\n",
    "    much detail) later in this book.\n",
    "\n",
    "[^6]: Conversely, if two threads from the same process are running on\n",
    "    different cores, then the MMU for each core will be pointing at the\n",
    "    same page table and thus use the same mappings.\n",
    "\n",
    "[^7]: You are no doubt familiar with this process from debugging C\n",
    "    programs.\n",
    "\n",
    "[^8]: In fact the x86 has a way of telling the CPU to switch page tables\n",
    "    when an exception occurs, but it's slow. It was used by early Linux\n",
    "    versions, but replaced in 1997 or so.\n",
    "\n",
    "[^9]: Similar to the program in\n",
    "    [\\[ch2:lst:hello\\]](#ch2:lst:hello){reference-type=\"autoref\"\n",
    "    reference=\"ch2:lst:hello\"}, but not exactly the same. I've\n",
    "    completely forgotten what program it was, actually.\n",
    "\n",
    "[^10]: In most compiled languages (e.g. C, C++) global variables which\n",
    "    aren't explicitly initialized have their values set to zero. The\n",
    "    compiler and linker lump these values together into a single\n",
    "    section, called BSS for an ancient IBM assembly language command\n",
    "    that is an abbreviation for something that no one remembers. Since\n",
    "    the entire section is going to contain all zero bytes, there is no\n",
    "    need to store its contents - just its starting address and length.\n",
    "\n",
    "[^11]: This is important for security reasons. The chapter on security\n",
    "    will talk more about the importance of double-checking user imputs\n",
    "    to keep a system secure.\n",
    "\n",
    "[^12]: In recent versions it's even more complicated than that, using a\n",
    "    table of all the locations in the kernel where the two functions are\n",
    "    invoked.\n",
    "\n",
    "[^13]: Why are the code sections for each process identical? Because (a)\n",
    "    they are mapped from the same file, and so started with the same\n",
    "    values, and (b) they are read-only, so those values haven't changed.\n",
    "    Is this safe? Doesn't it give a process access to another processes'\n",
    "    memory space? It's safe because each process still sees exactly the\n",
    "    same data as they would without sharing, and can't change that data\n",
    "    for other processes.\n",
    "\n",
    "[^14]: Most operating systems only check for the case where pages in\n",
    "    different processes map to exactly the same page in exactly the same\n",
    "    file. If you have two different executable files that happen to be\n",
    "    exact copies of each other, the OS will have no idea that they're\n",
    "    the same, and will happily load pages from both of them into memory\n",
    "    at the same time.\n",
    "\n",
    "[^15]: Example: `xterm` is the original graphical terminal emulator for\n",
    "    Unix, and uses very few fancy features. The program itself compiles\n",
    "    to about 372KB of machine instructions and some amount of data, but\n",
    "    it also uses 26 separate external libraries which add up to 5.6MB of\n",
    "    additional program space. A newer program, `gnome-terminal`, uses\n",
    "    only 300KB of memory for the program itself, but links in 48\n",
    "    libraries, for a total of 22MB of additional memory. Although both\n",
    "    of these examples are taken from Linux, both Apple OS X and Windows\n",
    "    use similar large libraries for the graphical interface.\n",
    "\n",
    "[^16]: In fact the system call returns twice, once in the parent and\n",
    "    once in the child\n",
    "\n",
    "[^17]: This measurement was made in 2012; more recent versions use more\n",
    "    memory.\n",
    "\n",
    "[^18]: When the hardware reads a page table entry into the TLB it checks\n",
    "    the A bit; if it is clear, then the hardware re-writes the entry\n",
    "    with the A bit set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395ff23-8297-49c9-871d-bb4eef1c0b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19c44d-dccd-4a37-b78c-c60ffaafc0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
