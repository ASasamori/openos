{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da51ecce-4235-413b-aad6-b596910ee3b8",
   "metadata": {},
   "source": [
    "(cont:vp:scheduling)=\n",
    "# Simple Scheduling\n",
    "\n",
    "A large number of scheduling policies have been developed over the years. Some of these are specialized for particular types of computing systems, while others aim to support more general-purpose systems. In this section, we will look at two broad categories of schedulers, and then discuss the different factors that the OS designer should take into consideration when developing a scheduling policy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4932bc-cbda-4cb6-9fc8-5958e849d822",
   "metadata": {
    "tags": []
   },
   "source": [
    "(cont:scheduling:scheduling:factors)=\n",
    "## Considerations for Scheduling Policies\n",
    "\n",
    "\n",
    "\n",
    "### Batch versus Preemptive\n",
    "\n",
    "Batch scheduling is a 'run to completion' model which means that once a job starts, it remains the active job on a CPU until it has completed. This mode of scheduling was used in early computers and is still used for some high-performance computing (HPC) systems. In our discussion of scheduling, we assume that batch jobs are finite, and will eventually complete. Preemptive scheduling is more familiar to the modern computer user because all consumer OS's use this model. In a preemptive scheduling system we use the notion of the time slice; a process is only active on a CPU while it is not blocked and it has not exhausted its time slice. This allows us to build interactive systems that can respond to user input and can handle jobs with unbounded run time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d97ec-f71b-4f69-9fa5-5c3e66c566bf",
   "metadata": {},
   "source": [
    "### Factors in Process Selection\n",
    "\n",
    "With all the parts in place to move processes on and off a CPU (i.e., the mechanism), we are only missing a method for choosing the next process to run on a CPU (i.e., the policy). Selecting the next process requires that the OS developer consider a number of possible criterion to optimize and to balance against each other. We must weigh things like responsiveness, turnaround time, throughput, predictability, fairness, and load on other parts of the system in making this decision, so let's take a look at what each of these considerations are.\n",
    "\n",
    "Responsiveness\n",
    "  : Responsiveness is the amount of time required for the system to respond to an event or a request. If a user is interacting with the system, they will likely notice if the scheduler is not prioritizing responsiveness because they have to wait for key strokes or other input to have their effect. \n",
    "\n",
    "Turnaround Time\n",
    "  : Turnaround time is the amount of time between a job submission and its termination. Minimizing this time often helps with throughput.\n",
    "\n",
    "Throughput\n",
    "  : We define throughput as the number of processes completed per unit of time. To optimize for throughput, we want to ensure that the active process stays on the CPU as long as it isn't blocked.\n",
    "\n",
    "Predictability\n",
    "  : We are not going to dive deeply into real-time computing, but there are classes of application which need to be certain of regular and predictable performance.\n",
    "\n",
    "```{Note}\n",
    "Real-time scheduling is used in a wide class of applications from industrial controls to vehicle management to robotics. Predictability is a key requirement in each of these cases. Think of the program or programs responsible for managing an airplane in flight. The developers make decisions for the software with a guarantee that certain calculations can be made at least N times a second. If this requirement is not met, we start seeing bad and possibly dangerous behavior.\n",
    "```\n",
    "\n",
    "Fairness\n",
    "  : Starvation in the context of scheduling is defined as a process never getting access to a CPU (for whatever reason). A functioning scheduler should not starve any process indefinitely. Achieving fairness may require more than simply not starving any process, however, we will use starvation-freedom as our fairness criteria.\n",
    "\n",
    "These requirements are often in tension with each other and designing a scheduling algorithm is an act of balancing trade offs for the requirements of the OS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9e6ca-d6ee-4a34-bcac-d294314063eb",
   "metadata": {},
   "source": [
    "(cont:scheduling:scheduling:policies)=\n",
    "## Simple Examples of Scheduling Policies\n",
    "\n",
    "Now that we have a collection of requirements, let's look at a few simple possibilities and see which of our requirements they meet well and which ones they fail. Our first two examples are for batch system scheduling, which means that each job runs to completion before a new job is selected. All batch scheduling scheduling policies are optimized for throughput, since the CPU time spent on context switches is minimized and the time to complete each job is minimized. \n",
    "\n",
    "The remaining examples are intended for preemptive scheduling.\n",
    "\n",
    "### First Come, First Served (FCFS)\n",
    "\n",
    "Just like waiting in line at the local government office, each process gets into a queue and the processor executes the first process in that queue until it completes. Then we repeat the same. This method is really simple and it meets our fairness requirement as we can prove that no process will be stalled indefinitely. However, this policy has poor behavior when we mix short, CPU intensive jobs with longer or I/O bound jobs. If a terminal process has to wait in a queue behind a long compilation task, it could look to the user as if the terminal is not responding to key strokes. Also, turnaround time for a job in this scheduler is entirely based on the length of the jobs preceding it in the queue.\n",
    "\n",
    "First come, first served meets our fairness requirement well, but it falls down on almost all the others. \n",
    "\n",
    "### Shortest Job First (SJF)\n",
    "\n",
    "Instead of using arrival time for selecting the next process, we sort the queue of processes by the amount of time they will take to run, and we keep the queue sorted by inserting processes by run time. This algorithm improves turnaround time and throughput over first come, first served but we can construct scenarios where long-running jobs are stalled indefinitely by having short jobs continually arriving on the system. Knowing how long a job will take to run when it first arrives is an additional complication for shortest job first scheduling. \n",
    "\n",
    "Shortest job first gives excellent throughput and can yield good turnaround time and responsiveness for systems with only short jobs. However, it totally fails on fairness and predictability.\n",
    "\n",
    "### Round Robin\n",
    "\n",
    "Our first preemptive scheduling algorithm is just like first come, first served but we have added the time slice so processes are no longer run to completion. In this model, we still have a single queue of processes in the Ready state, and processes can be added to it upon creation or when leaving the Blocked state. When a process becomes active, it is given a fixed amount of time to run, and when this time slice expires the OS interrupts the process and puts it at the back of the queue. \n",
    "\n",
    "```{Note}\n",
    "The preemptive scheduling models introduces a new parameter we need to set: the length of the time slice. We have to weigh the cost of changing processes against the interactivity requirements when deciding on the length of a time slice. Later on we will see systems that change the length based on usage patterns.\n",
    "```\n",
    "\n",
    "### Priority\n",
    "\n",
    "The core idea behind priority scheduling is that some processes may be more important than others and should be given access to the CPU first. To implement this policy, the OS maintains two or more priority queues which hold processes assigned to the corresponding priority. Runnable processes in a higher priority queue are run before runnable processes in lower priority queues. In general we assign higher priorities to I/O bound processes and lower priorities to CPU bound ones. Figure {numref}`priority-sched` shows a simple example of a system with 4 priority queues. In this snapshot, the next process to be given CPU time will be the first process in the priority 4 queue. Assuming no additions, the processes in queue 3 will not run until all of the ones in 4 have completed.\n",
    "\n",
    "```{figure} ../images/scheduling/priority-sched.png\n",
    "---\n",
    "name: priority-sched\n",
    "---\n",
    "A simple example of a system with 4 priority queues and runnable processes in several of the queues.\n",
    "```\n",
    "\n",
    "```{Note}\n",
    "It may seem counter-intuitive to assign high priority to I/O bound processes because they often do not make use of their full time slice. We do this because a process that is frequently blocking on I/O is more likely to be interactive and therefore have a user who will notice latency when the scheduler ignores the process for several periods.\n",
    "```\n",
    "\n",
    "### Lottery\n",
    "\n",
    "As the name suggests, in lottery scheduling the OS gives 'tickets' to each runnable process. When the scheduler needs to select a new process to run, it picks a ticket at random and the process holding that ticket runs. With a small modification, we can express priority in this method by assigning more tickets to high priority processes than low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ac18a-3b66-4f3d-9e53-cb0a19124822",
   "metadata": {},
   "source": [
    "These examples are not exhaustive, there are other algorithms for selecting the next runnable process, however these examples are meant to illustrate that there are a number of ways to approach this problem and this is an active area of research today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
