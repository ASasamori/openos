{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd81675d-f57f-4aa1-8ef6-11e9b0a156cb",
   "metadata": {},
   "source": [
    "# Synchronization -- Safety & Sequencing - FROM PETER's BOOK\n",
    "\n",
    "## Problem Introduction\n",
    "\n",
    "One of the key responsibilities of an operating system is that of\n",
    "synchronization---handling nearly simultaneous events in a reasonable\n",
    "way, and providing mechanisms for user applications to do so as well.\n",
    "\n",
    "In [\\[ch3:lst:bank\\]](#ch3:lst:bank){reference-type=\"autoref\"\n",
    "reference=\"ch3:lst:bank\"} we see a simplified example of a program to\n",
    "maintain a bank account balance at the Bank of Lost Funds. When running\n",
    "on a single CPU, the `deposit` function is trivially correct: after it\n",
    "completes execution, the value of `balance` will be `sum` greater than\n",
    "it was before the function was invoked.\n",
    "\n",
    "In [\\[ch3:fig:badbank\\]](#ch3:fig:badbank){reference-type=\"autoref\"\n",
    "reference=\"ch3:fig:badbank\"}, however, we see one possible result when\n",
    "this function is invoked by two threads nearly simultaneously. In this\n",
    "case thread 1 is interrupted after it has read the current value of\n",
    "`balance`, but before it could store the new value back to memory. The\n",
    "result is that the update performed by thread 2 is lost, being\n",
    "over-written by thread 1's computation, and after depositing a total of\n",
    "\\$150 to the account we have a final balance of \\$50.\n",
    "\n",
    "``` {#ch3:lst:bank float=\"\" label=\"ch3:lst:bank\" caption=\"Simple bank account example\"}\n",
    "money_t balance;\n",
    "function deposit(money_t sum) {\n",
    "   balance = balance + sum;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f65de-a3ce-4db9-a911-1852f68b0cb9",
   "metadata": {},
   "source": [
    "## Race Conditions and Mutual Exclusion\n",
    "\n",
    "Such errors are referred to as *race conditions*, because the result\n",
    "depends on a \"race\" between threads, where it is unknown which will\n",
    "execute some piece of code first.\n",
    "\n",
    "![Incorrect operation of banking example. An interrupt causes a thread\n",
    "switch *after* thread 1 has loaded `balance` into R1 and *before* it\n",
    "writes the updated value back into `balance`, so thread 2's update is\n",
    "lost.](../images/pb-figures/sync/sync-bank-flow.png){#ch3:fig:badbank width=\"90%\"}\n",
    "\n",
    "![Linked list corruption. (a) code for push and pop, (b) starting data\n",
    "structure, (c) interleaving of pop and push, (d) final state. Items 2\n",
    "and 3 are no longer on the list, and item 1 is both on the list and the\n",
    "return value from `pop`](../images/pb-figures/sync/sync-linked-list.png){#fig:sync:linked\n",
    "width=\"85%\"}\n",
    "\n",
    "Another example of such a race condition is shown in\n",
    "[\\[fig:sync:linked\\]](#fig:sync:linked){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:linked\"}(a) and (b), which shows a simple linked\n",
    "list, along with the code to use it as a push-down stack by pushing and\n",
    "popping elements. In\n",
    "[\\[fig:sync:linked\\]](#fig:sync:linked){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:linked\"}(c) and (d) we see what happens when a push\n",
    "and a pop conflict with each other, causing the list to become\n",
    "disconnected; in this case the right-hand side of the list is\n",
    "effectively \"lost\", with potentially disastrous consequences.\n",
    "\n",
    "The most insidious aspect of each of these race conditions is that they\n",
    "occur in otherwise bug-free code; in particular, there is no amount of\n",
    "testing which is guaranteed to find them.\n",
    "\n",
    "::: gsidebar\n",
    "In classic operating systems textbooks this is referred to as the\n",
    "*critical section problem*, defined as the case where there is a\n",
    "*critical section* of code which must be guarded against simultaneous\n",
    "execution. This is unfortunately a misleading term, as it should be\n",
    "obvious that it is the *data* that must be protected, not the code. For\n",
    "instance, in an object-oriented program a class may have two (or more)\n",
    "methods which can interfere with each other, even though different\n",
    "sections of code are being executed; conversely no interference will\n",
    "occur if any of these methods are invoked simultaneously on separate\n",
    "object instances.\n",
    ":::\n",
    "\n",
    "``` {#fig:sync:fakemutex float=\"t\" xleftmargin=\"1.3in\" framexleftmargin=\"1.3in\" label=\"fig:sync:fakemutex\" caption=\"Hypothetical operating system interface to create, use, and destroy mutexes.\"}\n",
    "mutex_t n = mutex_create()\n",
    " mutex_lock(n)\n",
    " mutex_unlock(n)\n",
    " mutex_destroy(n)\n",
    "```\n",
    "\n",
    "The solution to race conditions is fairly obvious, although not always\n",
    "simple: we identify all the cases where data must be protected against\n",
    "simultaneous modification or access, and prevent this from occuring[^1].\n",
    "To do this we create an object called a `mutex` (see\n",
    "[\\[fig:sync:fakemutex\\]](#fig:sync:fakemutex){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:fakemutex\"}) which has the ability to guard against\n",
    "simultaneous access. This object has two methods, `lock` and `unlock`,\n",
    "and the following properties:\n",
    "\n",
    "::: itemize*\n",
    "Given a mutex `m`, once some thread T1 returns from `m.lock()`, no other\n",
    "thread T2 will return from `m.lock()` until T1 enters `m.unlock()`.\n",
    "\n",
    "If thread T1 is holding mutex [m](m){.uri} (i.e. it has entered and\n",
    "returned from [m.lock](m.lock){.uri} and T2 is waiting for [m](m){.uri}\n",
    "(it has entered but not returned from [m.lock()](m.lock()){.uri}), then\n",
    "when T1 enters [m.ulock()](m.ulock()){.uri}, T2 (or some other thread\n",
    "blocked on [m](m){.uri}) will \"promptly\" return from\n",
    "[m.lock()](m.lock()){.uri}.\n",
    ":::\n",
    "\n",
    "(these properties are also termed *mutual exclusion*---hence the name\n",
    "mutex---and *progress*, and are two of the three formal requirements for\n",
    "a solution to the critical section problem.)\n",
    "\n",
    "When thread T1 returns from `m.lock()`, we often say that T1 has\n",
    "*acquired* the mutex `m`, or that it is *holding* it; when T1 invokes\n",
    "`m.unlock()` it *releases* the mutex. Note that other threads are free\n",
    "to *call* the lock method on `m` while `m` is held by T1; however none\n",
    "of those threads will *return* from the call until the mutex is\n",
    "released. If T1 were to hold the mutex for a long time, this would delay\n",
    "the other threads; if it fails to ever release the mutex (e.g. due to\n",
    "raising an exception before the call to `unlock()`) it would be a\n",
    "serious bug, typically causing the program to freeze.\n",
    "\n",
    "We can now write a thread-safe version of our bank account object, as\n",
    "seen in\n",
    "[\\[fig:sync:safebank\\]](#fig:sync:safebank){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:safebank\"}. It avoids the race condition described\n",
    "in the beginning of the chapter by using a per-instance mutex to guard\n",
    "operations which modify the balance. By doing this we have made the\n",
    "modification of the balance *atomic*[^2], at least with respect to any\n",
    "other code which properly locks the mutex---i.e. it appears to happen as\n",
    "a single operation, with any other modification happening either before\n",
    "or after, but not simultaneously.\n",
    "\n",
    "``` {#fig:sync:safebank float=\"\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" framexleftmargin=\"1in\" xleftmargin=\"1.0in\" label=\"fig:sync:safebank\" caption=\"Safe bank account object. Note that other actions which modify the balance, such as \\\\texttt{withdraw()}, must lock mutex \\\\texttt{m} as well.\"}\n",
    "object account is:\n",
    "    mutex  m\n",
    "    int    balance\n",
    "\n",
    "    method deposit(int amount):\n",
    "        m.lock()\n",
    "        balance = balance + amount\n",
    "        m.unlock()\n",
    "\n",
    "    method get_balance():\n",
    "        return balance\n",
    "```\n",
    "\n",
    "``` {#fig:sync:safebank2 float=\"\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" label=\"fig:sync:safebank2\" caption=\"Bank account object with more complex state. To avoid observing invalid state (e.g. a cents value greater than 99) we must lock the mutex when reading as well as writing.\"}\n",
    "object account is:\n",
    "    mutex   m\n",
    "    int     balance_dollars\n",
    "    int     balance_cents\n",
    "\n",
    "    method deposit(int dollars,  int cents):\n",
    "        m.lock()\n",
    "        balance_cents = balance_cents + cents\n",
    "        if balance_cents >= 100:\n",
    "            balance_dollars = balance_dollars + 1\n",
    "            balance_cents = balance_cents - 100\n",
    "        balance_dollars = balance_dollars + dollars\n",
    "        m.unlock()\n",
    "\n",
    "    method get_balance(out &d, out &c):  // d,c are outputs\n",
    "        m.lock()\n",
    "        d = balance_dollars\n",
    "        c = balance_cents\n",
    "        m.unlock()\n",
    "```\n",
    "\n",
    "In [\\[fig:sync:safebank\\]](#fig:sync:safebank){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:safebank\"} we can (on most computers) safely read\n",
    "the balance without locking the mutex, because the hardware can usually\n",
    "be trusted to perform a read of a single integer atomically. Another way\n",
    "to state this is that the object is in a *safe* state at all times---it\n",
    "changes atomically from one safe state to another. In\n",
    "[\\[fig:sync:safebank2\\]](#fig:sync:safebank2){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:safebank2\"} we see a bank account object with a\n",
    "slightly more complex state, representing integer dollars and cents\n",
    "separately; in this case reading the object state in the middle of an\n",
    "update could give incorrect results, e.g. showing $balance\\_cents>99$.\n",
    "(more serious problems such as null pointer errors can occur when\n",
    "accessing complex data structures such as linked lists or trees during\n",
    "an update) To prevent this, the code in\n",
    "[\\[fig:sync:safebank2\\]](#fig:sync:safebank2){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:safebank2\"} locks the object *when observing its\n",
    "state*, so that it only sees the consistent state found after an update\n",
    "has fully completed.\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7ff23-d1ab-4b2c-a8a3-bfdd2b3b6e5f",
   "metadata": {},
   "source": [
    "## Implementing Mutexes\n",
    "\n",
    "So mutexes are great, but how do they actually work? In\n",
    "[\\[fig:sync:fakemutex\\]](#fig:sync:fakemutex){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:fakemutex\"} we saw a hypothetical system call\n",
    "interface which allows us to create, destroy, lock and unlock mutexes.\n",
    "Internal to the OS we can assume that each mutex has a state---locked or\n",
    "unlocked---and a list of threads waiting for the mutex. If a process\n",
    "calls [mutex_lock](mutex_lock){.uri} on an unlocked mutex, the mutex is\n",
    "marked as locked and [mutex_lock](mutex_lock){.uri} returns immediately.\n",
    "If the mutex is locked, then the call is treated almost exactly like\n",
    "waiting for I/O: the OS puts the thread on the mutex wait queue, and\n",
    "then switches to the next active thread. When\n",
    "[mutex_unlock](mutex_unlock){.uri} is called, the OS takes the first\n",
    "thread (if any) off the queue and puts it back on the active list.\n",
    "\n",
    "So now that we know exactly how our mutex system calls are supposed to\n",
    "behave, how do we implement them? In addition, how does the operating\n",
    "system protect its own data structures, which (in e.g. Linux and\n",
    "Windows) reside in a single address space and are accessed from not only\n",
    "multiple user processes (via system calls) and kernel threads, but also\n",
    "from exception handlers for e.g. page faults and hardware interrupts?\n",
    "\n",
    "On a single-processor system this is fairly straightforward. Code runs\n",
    "in a straight line unless it is interrupted by a hardware interrupt or\n",
    "an exception such as a page fault, so all we need to do is to (a)\n",
    "disable interrupts, and (b) ensure that the operating system code and\n",
    "data (or at least the code and data needed for mutexes) is always mapped\n",
    "into physical memory, to avoid page faults.\n",
    "\n",
    "(Note that user-level code is not allowed to disable interrupts, as\n",
    "doing so for more than a brief period is likely to crash the machine.)\n",
    "\n",
    "``` {#lst:sync:osmutexA float=\"\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" caption=\"Simple single-CPU kernel mutex. The ``locked'' flag and list of waiting processes are guarded by disabling interrupts\" label=\"lst:sync:osmutexA\"}\n",
    "structure mutex:\n",
    "    bool locked = False // guarded by IRQ disable\n",
    "    queue waitlist      // waiting threads (also guarded)\n",
    "\n",
    "mutex_lock(mutex m):\n",
    "    disable_interrupts()\n",
    "    if not m.locked\n",
    "        m.locked = True\n",
    "        enable_interrupts()\n",
    "    else:\n",
    "        pause(current_process) // remove it from active list\n",
    "        m.waitlist.add(current_process)\n",
    "        enable_interrupts()\n",
    "        sleep()                // wake here when mutex acquired\n",
    "\n",
    "mutex_unlock(mutex m):\n",
    "    disable_interrupts()\n",
    "    if waitlist is empty:\n",
    "        m.locked = False\n",
    "        enable_interrupts()\n",
    "    else\n",
    "        local next_thread = m.waitlist.pop_from_head()\n",
    "        enable_interrupts()\n",
    "        wake(next_thread) // add it to the active list\n",
    "```\n",
    "\n",
    "In [\\[lst:sync:osmutexA\\]](#lst:sync:osmutexA){reference-type=\"autoref\"\n",
    "reference=\"lst:sync:osmutexA\"} we see a mutex implementation based on\n",
    "this. We assume the same context-switching structure used in\n",
    "[\\[fig:ch2:serialin2\\]](#fig:ch2:serialin2){reference-type=\"autoref\"\n",
    "reference=\"fig:ch2:serialin2\"} in the previous chapter, with a thread\n",
    "control structure containing fields such as the saved stack pointer as\n",
    "well as links for creating lists:\n",
    "\n",
    "- [current](current){.uri} points to the currently running thread\n",
    "- [active](active){.uri} is a list of other threads ready to run\n",
    "- [sleep](sleep){.uri} pops the next runnable thread from\n",
    "- [active](active){.uri}, assigns it to [current](current){.uri}, and\n",
    "switches to it[^3].\n",
    "- [wake](wake){.uri} appends a thread to the active list so that it can\n",
    "run again.\n",
    "\n",
    "\n",
    "On a single-CPU system the fields of the mutex structure are protected\n",
    "from race conditions, as no interrupts will occur during modifications.\n",
    "We can see that our mutex requirements will be met, by noting that:\n",
    "\n",
    "- the first thread to call [lock(m)](lock(m)){.uri} will set\n",
    "[m.locked](m.locked){.uri} to true and return immediately.\n",
    "\n",
    "- if another thread calls [lock(m)](lock(m)){.uri} before the mutex is\n",
    "unlocked, it will queue itself on [m.waitq](m.waitq){.uri} and sleep.\n",
    "\n",
    "- when [unlock(m)](unlock(m)){.uri} is called, if there are any threads\n",
    "waiting then the first one will be woken up (and thus continue from its\n",
    "- [sleep](sleep){.uri} call and return from [lock(m)](lock(m)){.uri} the\n",
    "next time it is scheduled), and the mutex will remain locked;\n",
    "\n",
    "- if no threads are waiting the mutex will be unlocked.\n",
    "\n",
    "::: gsidebarN\n",
    "16 An exercise for the reader - many textbooks describe Dekker's and\n",
    "Peterson's algorithms for mutual exclusion, which use normal memory load\n",
    "and store instructions to provide mutual exclusion. Try implementing\n",
    "Peterson's algorithm as described in Wikipedia, with two threads each\n",
    "looping N times, each time (a) entering the critical section, (b)\n",
    "incrementing a counter, and (c) leaving the critical section. For large\n",
    "N (e.g. $10^7$) does the counter always get incremented 2N times? Why\n",
    "not? (feel free to ask in class if you don't find the answer)\n",
    ":::\n",
    "\n",
    "On a multi-core system the problem is more complicated, however, as the\n",
    "CPU cores are all executing simultaneously, accessing the same memory,\n",
    "whether interrupts are enabled or not. Implementing a mutex on a\n",
    "multi-core system requires coordinating via the memory system shared\n",
    "between all the CPUs, using special instructions which are guaranteed to\n",
    "execute uninterrupted by instructions running on any of the other CPU\n",
    "cores.\n",
    "\n",
    "``` {#lst:sync:spinlock float=\"\" caption=\"Spinlock implementation. If the lock contains 0, it is unlocked; if 1, then it is locked, in which case a second thread (or CPU) trying to acquire it will ``spin'' (i.e. loop) until it is released.\" label=\"lst:sync:spinlock\"}\n",
    "typedef int spinlock_t \n",
    "        spin_lock(spinlock_t *lock_addr):\n",
    "            register r = 1\n",
    "            while r == 1:\n",
    "                SWAP r, lock_addr\n",
    "\n",
    "        spin_unlock(spinlock_t *lock_addr):\n",
    "            *lock_addr = 0\n",
    "```\n",
    "\n",
    "There are a number of specialized CPU instructions which are typically\n",
    "provided to implement mutual exclusion; we will consider one of them,\n",
    "the atomic SWAP instruction[^4]:\n",
    "\n",
    "-   SWAP *register*, *address*\n",
    "\n",
    "This instruction swaps the contents of a register with the data in a\n",
    "specified memory location, and unlike normal instructions it is\n",
    "guaranteed to do so atomically. In other words, no matter how many CPU\n",
    "cores are trying to swap with the same memory location simultaneously,\n",
    "one of them will do so first, another second, and so on, and every CPU\n",
    "will see the location change values in the same order.\n",
    "\n",
    "This is in contrast to normal load/store instructions, where different\n",
    "CPU cores may see differences in the order in which changes occur. This\n",
    "is not surprising when you consider that each CPU is handling multiple\n",
    "instructions at once, possibly out of order, and writing into cache\n",
    "lines which are only later flushed to main memory. For instance, if CPU\n",
    "1 writes to cache line A and then to cache line B, they could\n",
    "conceivably be flushed to memory in the opposite order, so while CPU 1\n",
    "sees A written before B, other CPUs see B written before A. Although\n",
    "it's possible to achieve consistent ordering---that's what atomic\n",
    "instructions do---it's much slower.\n",
    "\n",
    "![Spinlock operation. Here we see CPU 1 acquire the lock, after which\n",
    "CPU 2 and then CPU 0 attempt to acquire it. After CPU 1 releases the\n",
    "lock (by writing 0) one of the waiting CPUs (in this case 0) is then\n",
    "able to acquire it.](../images/pb-figures/sync/spin-lock.png){#fig:sync:spinlockop\n",
    "width=\"60%\"}\n",
    "\n",
    "The SWAP instruction allows us to implement what is called a *spinlock*,\n",
    "as shown in\n",
    "[\\[lst:sync:spinlock\\]](#lst:sync:spinlock){reference-type=\"autoref\"\n",
    "reference=\"lst:sync:spinlock\"}. An example of its operation is shown in\n",
    "[\\[fig:sync:spinlockop\\]](#fig:sync:spinlockop){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:spinlockop\"}: in effect the 0 value is treated as a\n",
    "token that is passed between waiting CPUs (or threads) and the lock\n",
    "memory location. This lock is extremely simple, and by making use of the\n",
    "hardware-provided atomic SWAP instruction, it guarantees mutual\n",
    "exclusion. However as we see in the figure it can be (a) unfair, as it\n",
    "does not respect the order in which CPUs begin to wait for the lock, and\n",
    "(b) inefficient, as CPUs 2 and 0 are unable to perform any work while\n",
    "waiting. We therefore use spinlocks to guard very short pieces of code,\n",
    "and then use these pieces of code to construct efficient and\n",
    "well-behaved primitives for applications to use.\n",
    "\n",
    "``` {#lst:sync:osmutex float=\"\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" caption=\"Multi-core-safe implementation of the mutex from \\\\autoref{lst:sync:osmutexA}, with spinlock for additional protection\" label=\"lst:sync:osmutex\" belowskip=\"0in\"}\n",
    "structure mutex:\n",
    "    int  spinlock\n",
    "    bool free = True  // guarded by spinlock\n",
    "    queue waitlist    // waiting threads, guarded by spinlock\n",
    "\n",
    "mutex_lock(mutex m):\n",
    "    disable_interrupts()\n",
    "    spin_lock(&m.spinlock)\n",
    "    if m.free\n",
    "        m.free = False\n",
    "        spin_unlock(&m.spinlock)\n",
    "        enable_interrupts()\n",
    "    else:\n",
    "        pause(current_process) // remove it from active list\n",
    "        m.waitlist.add(current_process)\n",
    "        spin_unlock(&m.spinlock)\n",
    "        enable_interrupts()\n",
    "        sleep()                // wake here when mutex acquired\n",
    "\n",
    "mutex_unlock(mutex m):\n",
    "    disable_interrupts()\n",
    "    spin_lock(&m.spinlock)\n",
    "    if waitlist is empty:\n",
    "        m.free = True\n",
    "        spin_unlock(&m.spinlock)\n",
    "        enable_interrupts()\n",
    "    else\n",
    "        local next_thread = m.waitlist.pop_from_head()\n",
    "        spin_unlock(&m.spinlock)\n",
    "        enable_interrupts()\n",
    "        wake(next_thread) // add it to the active list\n",
    "```\n",
    "\n",
    "A spinlock-enhanced version of the mutex in\n",
    "[\\[lst:sync:osmutexA\\]](#lst:sync:osmutexA){reference-type=\"autoref\"\n",
    "reference=\"lst:sync:osmutexA\"} is shown in\n",
    "[\\[lst:sync:osmutex\\]](#lst:sync:osmutex){reference-type=\"autoref\"\n",
    "reference=\"lst:sync:osmutex\"}; it is identical except for the addition\n",
    "of a spinlock, which is used in addition to disabling interrupts to\n",
    "guard the [locked](locked){.uri} flag and wait queue.\n",
    "\n",
    "This implementation retains almost all the efficiency of the single-CPU\n",
    "version, as the spinlock is never held for more than a few instructions,\n",
    "limiting the length of time that other CPUs are stuck busy-waiting[^5].\n",
    "Unlike the basic spinlock, this mutex is also fair, as waiting threads\n",
    "will be queued and acquire the mutex in FIFO order. (at most, any\n",
    "unfairness in the underlying spinlock mechanism will effect the order in\n",
    "which threads go onto the list, not how many turns they get holding the\n",
    "mutex.)\n",
    "\n",
    "::: gsidebarN\n",
    "6 A question for the reader - why is it important to unlock the spinlock\n",
    "and enable interrupts before calling `sleep()` in `mutex_lock`?\n",
    ":::\n",
    "\n",
    "More formally, what we mean by \"fair\" in this case is *bounded\n",
    "waiting*---i.e. no thread can be \"starved\" while other threads\n",
    "repeatedly acquire and release the mutex. (this is the third requirement\n",
    "for solutions to the critical section problem)\n",
    "\n",
    "In particular, if thread A is waiting for the mutex, bounded waiting\n",
    "means that another thread B cannot acquire and then release it many\n",
    "times while A is still waiting. (note that spinlocks cannot guarantee\n",
    "this property, as any waiting thread can acquire the lock, regardless of\n",
    "how long it has been waiting.) If multiple threads (on separate CPUs)\n",
    "call [mutex_lock](mutex_lock){.uri} at once, the spinlock will determine\n",
    "what order they will be added on the queue, but the FIFO ordering of the\n",
    "queue ensures that if a thread acquires the mutex and releases it, when\n",
    "it tries to lock the mutex again it will go to the tail of the line.\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "![Scenario for question\n",
    "[\\[prob:synchro:2:1\\]](#prob:synchro:2:1){reference-type=\"ref\"\n",
    "reference=\"prob:synchro:2:1\"}](../images/pb-figures/sync/sync-badswap.png){#fig:sync:badswap\n",
    "width=\"70%\"}\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddccb979-f3bf-4095-b636-c53932ebb99b",
   "metadata": {},
   "source": [
    "## The Bounded Buffer Problem and Semaphores\n",
    "\n",
    "Mutexes can be used to *prevent* certain orders of execution---e.g.\n",
    "multiple threads executing certain operations at the same time---but\n",
    "what if we want to *cause* a certain order of execution? (for instance,\n",
    "waking a thread which is waiting for keystroke input.) We refer to this\n",
    "as *synchronization*, and to the primitives which are used for this\n",
    "purpose as *synchronization primitives*.\n",
    "\n",
    "To begin we'll examine a \"classic\" or pedagogical[^6] synchronization\n",
    "problem frequently used as an example of multi-threaded programming: the\n",
    "*Bounded Buffer Problem*, which may be defined as follows:\n",
    "\n",
    "::: enumerate*\n",
    "An object `buffer` has methods `put` and `get`.\n",
    "\n",
    "Successive calls to `buffer.put(item)` insert items into the buffer.\n",
    "\n",
    "Successive calls to `item = buffer.get()` remove items from the buffer\n",
    "in the same order as they were inserted.\n",
    "\n",
    "If the buffer contains no items, `buffer.get()` will block until an item\n",
    "is inserted.\n",
    "\n",
    "If the buffer contains N items, `buffer.put()` will block until an item\n",
    "is removed.\n",
    ":::\n",
    "\n",
    "We can start with a single-threaded version of the bounded buffer. In\n",
    "this case parts 3 and 4 of the definition must be modified, as no other\n",
    "thread will arrive to insert or remove an item; instead we will return\n",
    "NULL if no item is available, and ERROR if the buffer is full, as seen\n",
    "in [\\[fig:sync:bb\\]](#fig:sync:bb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:bb\"}.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" xleftmargin=\"0in\" framexleftmargin=\"0in\" multicols=\"2\" frame=\"none\"}\n",
    "list buffer\n",
    "\n",
    "put(item):\n",
    "    if len(buffer) >= N\n",
    "        return ERROR\n",
    "    else\n",
    "        buffer.add_tail(item)\n",
    "        return OK\n",
    "\n",
    "get(item):\n",
    "    if len(buffer) == 0\n",
    "        return NULL\n",
    "    else\n",
    "        return buffer.remove_head()\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "By adding a mutex we can safely handle multiple threads, as seen in\n",
    "[\\[fig:sync:tsbb\\]](#fig:sync:tsbb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:tsbb\"}.[^7]\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" xleftmargin=\"0in\" framexleftmargin=\"0in\" multicols=\"2\" frame=\"none\"}\n",
    "mutex m\n",
    "list  buffer\n",
    "\n",
    "put(item):\n",
    "    m.lock()\n",
    "    if len(buffer) >= N\n",
    "        result = ERROR\n",
    "    else\n",
    "        buffer.add_tail(item)\n",
    "        result = OK\n",
    "    m.unlock()\n",
    "    return result\n",
    "\n",
    "get(item):\n",
    "    m.lock()\n",
    "    if len(buffer) == 0\n",
    "        result = NULL\n",
    "    else\n",
    "        result = buffer.remove_head()\n",
    "    m.unlock()\n",
    "    return result\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "However we still don't have a full solution to the bounded buffer\n",
    "problem---we need to not only protect the threads from each other,\n",
    "\n",
    "::: gsidebarN\n",
    "10 The two operations on a semaphore were originally given Dutch\n",
    "abbreviations *P* and *V* by their inventor, Edsger Dijkstra. Since then\n",
    "they have also been called *down* and *up*, *acquire* and *release*,\n",
    "*wait* and *signal*, *await* and *notify*, etc. We will call them *wait*\n",
    "and *signal*.\n",
    ":::\n",
    "\n",
    "but to *coordinate* or *synchronize* them, so that e.g. one thread\n",
    "sleeps in `get()` until another thread invokes `put()`. We haven't seen\n",
    "how to use a mutex for this purpose, and in fact many real-world mutex\n",
    "implementations cannot be used to do this[^8].\n",
    "\n",
    "Instead we introduce a new object called the *counting semaphore*, which\n",
    "is deliberately designed for synchronizing the actions of multiple\n",
    "threads. Like a mutex, a semaphore is an OS-provided object; however an\n",
    "initial count N is specified when it is created. It has two methods,\n",
    "`wait()` and `signal()`, with the following behavior:\n",
    "\n",
    "::: itemize*\n",
    "For semaphore $S$ with initial count $N$, if $N_w$ is the total number\n",
    "of times any thread has returned from `S.wait()`, and $N_s$ is the\n",
    "number of times any thread has entered `S.signal()`, then\n",
    "$N_w-N_s \\le N$.\n",
    ":::\n",
    "\n",
    "Intuitively a semaphore may be understood by assuming that it maintains\n",
    "a count initialized to $N$. When *wait* is called it (a) waits until the\n",
    "count is greater than zero, then (b) decrements the count and returns.\n",
    "Calling *signal* increments the count, possibly waking up one of the\n",
    "threads waiting for $count > 0$. In practice this is done by maintaining\n",
    "a list of waiting threads; if there are threads waiting on this list\n",
    "then *signal* wakes the first one rather than incrementing the count.\n",
    "\n",
    "::: gsidebarN\n",
    "10 A question for the reader - if you are given a function\n",
    "`NewSemaphore0()` which creates a new counting semaphore with its count\n",
    "initialized to 0, how would you write a function `NewSemaphore(N)` which\n",
    "returns a semaphore initialized to an arbitrary positive count N?.\n",
    ":::\n",
    "\n",
    "A *binary semaphore* is a semaphore which can only take on the values 0\n",
    "and 1, and is the same thing as a mutex. (well, disregarding\n",
    "implementation details of many mutexes, such as ownership checks.) Note\n",
    "that this behaves slightly differently from a counting semaphore\n",
    "initialized to 1, specifically in the case where `signal()` is called\n",
    "multiple times without intervening calls to `wait`[^9].\n",
    "\n",
    "Note that the behavior of the wait and signal methods of a counting\n",
    "semaphore are almost exactly the same behaviors as those we want for the\n",
    "put and get methods in our bounded buffer, keeping track of a count and\n",
    "blocking when that count reaches a limit. Using one semaphore to track\n",
    "the number of items in the buffer, and another to track the number of\n",
    "free spaces, we have the implementation in\n",
    "[\\[fig:sync:bb3\\]](#fig:sync:bb3){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:bb3\"}.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" xleftmargin=\"0in\" framexleftmargin=\"0in\" multicols=\"2\" frame=\"none\"}\n",
    "mutex     m\n",
    "list      buffer\n",
    "semaphore space = semaphore(N)\n",
    "semaphore items = semaphore(0)\n",
    "\n",
    "put(item):\n",
    "    space.wait()\n",
    "    m.lock() \n",
    "    buffer.add_tail(item)\n",
    "    m.unlock()\n",
    "    items.signal()\n",
    "\n",
    "get(item):\n",
    "    items.wait()\n",
    "    m.lock() \n",
    "    result = buffer.remove_head()\n",
    "    m.unlock()\n",
    "    space.signal()\n",
    "    return result\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Note that we still need a mutex to protect the linked list, as although\n",
    "the semaphore limits the number of threads which can be modifying the\n",
    "list simultaneously, that limit is greater than 1. (alternately we could\n",
    "implement a \"thread-safe linked list\" class which included a mutex, thus\n",
    "simplifying any threaded code which used it.)\n",
    "\n",
    "![Operation of bounded buffer from\n",
    "[\\[fig:sync:bb3\\]](#fig:sync:bb3){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:bb3\"}, limit=2](../images/pb-figures/sync/boundedbuf.png){#fig:sync:bb4\n",
    "width=\"80%\"}\n",
    "\n",
    "In [\\[fig:sync:bb4\\]](#fig:sync:bb4){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:bb4\"} we see this in operation. With a limit of 2\n",
    "items, the first two calls to `put` return immediately; however the\n",
    "third one blocks as the \"space\" semaphore has dropped to zero. When a\n",
    "call to `get` from thread 4 increments the \"space\" semaphore again,\n",
    "thread 3 is able to return from `space.wait()`, decrementing its value\n",
    "to zero again, and can then insert its item into the list.\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea592bf-9e55-4af5-a106-4a1b60b0eb15",
   "metadata": {},
   "source": [
    "## Deadlock\n",
    "\n",
    "Consider the ways that the following code can execute, with thread 1\n",
    "executing `foo()`, and thread 2 executes `bar()`:\n",
    "\n",
    "    mutex A, B;\n",
    "\n",
    "    foo:\n",
    "        lock A\n",
    "        lock B\n",
    "         ...\n",
    "        unlock B\n",
    "        unlock A\n",
    "\n",
    "\n",
    "\n",
    "    bar:\n",
    "        lock B\n",
    "        lock A\n",
    "         ...\n",
    "        unlock A\n",
    "        unlock B\n",
    "\n",
    "![Three possible interleavings of `foo()` and\n",
    "`bar()`.](../images/pb-figures/sync/sync-deadlk-1.png){#fig:sync:deadlk width=\"\\\\textwidth\"}\n",
    "\n",
    "![Three possible interleavings of `foo()` and\n",
    "`bar()`.](../images/pb-figures/sync/sync-deadlk-2.png){#fig:sync:deadlk width=\"\\\\textwidth\"}\n",
    "\n",
    "![Three possible interleavings of `foo()` and\n",
    "`bar()`.](../images/pb-figures/sync/sync-deadlk-3.png){#fig:sync:deadlk width=\"\\\\textwidth\"}\n",
    "\n",
    "\\\n",
    "\n",
    "\\(a\\)\n",
    "\n",
    "\\(b\\)\n",
    "\n",
    "\\(c\\)\n",
    "\n",
    "::: itemize*\n",
    "If thread 1 starts early enough, we may see the result in\n",
    "[\\[fig:sync:deadlk\\]](#fig:sync:deadlk){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:deadlk\"}(a), where thread 1 or alternately thread 2)\n",
    "finishes completely before thread 2 starts.\n",
    "\n",
    "Or, if they start close enough in time, they may overlap somewhat but\n",
    "still complete successfully, as in\n",
    "[\\[fig:sync:deadlk\\]](#fig:sync:deadlk){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:deadlk\"}(b).\n",
    "\n",
    "But if they start at about the same time, there is a chance of getting\n",
    "the situation in\n",
    "[\\[fig:sync:deadlk\\]](#fig:sync:deadlk){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:deadlk\"}(c), where both threads are blocking on\n",
    "their second lock operation.\n",
    ":::\n",
    "\n",
    "This is a deadlock, where two threads are each waiting for a lock held\n",
    "by the other thread. As you can see, it can halt program execution just\n",
    "as completely as a program crash or infinite loop, and typically\n",
    "requires the application to be killed and restarted.\n",
    "\n",
    "### Classic Conditions for Deadlock\n",
    "\n",
    "Intuitively a deadlock is when multiple processes (or threads) are\n",
    "waiting for locks held by other processes in the group, each unable to\n",
    "give up the locks it is holding before it acquires the lock that it is\n",
    "waiting for. More generally, deadlocks can occur when acquiring not just\n",
    "locks, but other sorts of *resources*: e.g. each process might be trying\n",
    "to allocate N buffers out of a fixed-sized pool.\n",
    "\n",
    "Phrased more formally, there are four classic conditions for deadlock\n",
    "among multiple processes contending for resources:\n",
    "\n",
    "\n",
    "1. **Mutual exclusion**: A deadlock requires resources (like mutexes) that\n",
    "can only be held by one process\n",
    "\n",
    "2. **Hold and wait**: A process holds one or more acquired resources and\n",
    "then blocks waiting to acquire another resource\n",
    "\n",
    "3. **No preemption**: Resources are only released when a process is done\n",
    "with them and calls the release function (like unlock). One process\n",
    "cannot force another to release a resource.\n",
    "\n",
    "4. **Circular wait**: Given the three prior conditions, if there is a\n",
    "circular wait then there is a deadlock\n",
    "\n",
    "\n",
    "The processes that deadlock can be any form of concurrent activity:\n",
    "threads, processes, or interrupts vs. a foreground process. There can be\n",
    "any number of processes, and in some cases a process can even deadlock\n",
    "with itself. Finally, the resources being acquired can be anything which\n",
    "has both the mutual exclusion and hold and wait properties. These\n",
    "resources aren't just mutexes and semaphores, but things like memory\n",
    "buffers or the process of obtaining exclusive access to a file.\n",
    "\n",
    "Finally, there is a deadlock case not quite covered by these\n",
    "conditions---the one where the programmer forgot to release a lock. Try\n",
    "not to do that.\n",
    "\n",
    "### Avoiding Deadlock: Lock Ranking\n",
    "\n",
    "::: wrapfigure\n",
    "r0in \\[8\\]\\[0in\\]\n",
    ":::\n",
    "\n",
    "If any one of these four conditions can be avoided, deadlock cannot\n",
    "occur. If locks are always acquired in the same order, no matter what\n",
    "thread is acquiring them via which code path, then there will be no\n",
    "circular wait and thus no deadlock, as you can see in\n",
    "[\\[fig:sync:ordered\\]](#fig:sync:ordered){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:ordered\"}.\n",
    "\n",
    "Using lock ranking requires three steps:\n",
    "\n",
    "::: compactenum\n",
    "Find all locks in a program.\n",
    "\n",
    "Number them in the order (\"rank\") in which they should be acquired\n",
    "\n",
    "Verify that no lock is acquired out of order, via e.g. the use of debug\n",
    "assertions and extensive testing.\n",
    ":::\n",
    "\n",
    "This technique is difficult to implement, and cannot be used in every\n",
    "case. An example of its use is in the VMware virtualization product,\n",
    "where several hundred (as of when I worked there in 2007) locks are\n",
    "ranked in order, and beta builds will assert and crash if a\n",
    "lower-priority lock is acquired while holding a higher-priority one.\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95efbb8e-fa4d-4bad-b875-ee63782edfce",
   "metadata": {},
   "source": [
    "## Monitors\n",
    "\n",
    "Semaphores do a good job of solving simple problems like the bounded\n",
    "buffer, and in theory are sufficient to solve any synchronization\n",
    "problem[^10], but become quite complicated to use when a problem can't\n",
    "be solved by simple counting. As an example, we'll look at what we'll\n",
    "call the *Weighted Bounded Buffer Problem*, which differs from the\n",
    "bounded buffer problem in these ways:\n",
    "\n",
    "::: enumerate*\n",
    "Each item has a weight, `item.weight`\n",
    "\n",
    "The total weight of the items in the buffer cannot exceed N. If\n",
    "`buffer.put()` would cause this limit to be exceeded, then it will block\n",
    "until enough space is available.\n",
    ":::\n",
    "\n",
    "At first it seems like it would be sufficient for `put` and `get` to\n",
    "call `signal` and `wait` *W* times if *W* is the weight of the item\n",
    "being added or removed; however this could cause problems if two threads\n",
    "called `put` or `get` simultaneously, and is not possible at all if\n",
    "`weight` is a continuous (i.e. floating point) value. Unlike the simple\n",
    "case, we're going to have to write our own code to maintain counts and\n",
    "make decisions about when to sleep, and if we do this with semaphores\n",
    "it's going to be quite ugly.\n",
    "\n",
    "Instead we introduce a programming language feature for synchronization\n",
    "called a *monitor*. Unlike mutexes and semaphores, which are operating\n",
    "system-defined types, a monitor is a special type of user-defined object\n",
    "or class, where the language provides support for constructing\n",
    "user-defined synchronization behavior.\n",
    "\n",
    "In particular, a monitor has (a) special instance variables called\n",
    "*conditions*, which support the methods `wait`, `signal`, and\n",
    "`broadcast`, and (b) a per-instance *implicit mutex*, which ensures that\n",
    "only one thread is *in* the monitor (instance) at any one time,\n",
    "executing method code. More precisely, what we mean by this is:\n",
    "\n",
    "::: itemize*\n",
    "A thread *enters* the monitor by entering one of its methods. Any number\n",
    "of threads can try to invoke methods on the same instance at once, but\n",
    "only one will get through and begin to execute method code.\n",
    "\n",
    "A thread *leaves* the monitor when it returns from a method. This is\n",
    "pretty obvious.\n",
    "\n",
    "A thread also *leaves* the monitor when it calls wait on any of the\n",
    "instance condition variables. This is less obvious, but important, as\n",
    "otherwise no other thread would be able to enter the monitor to wake it\n",
    "up.\n",
    "\n",
    "A thread then *enters* the monitor again when it returns from wait. Note\n",
    "that this can't actually happen until *after* the thread which is\n",
    "currently in the monitor---usually the one that called notify---leaves\n",
    "the monitor.\n",
    ":::\n",
    "\n",
    "When a thread calls `wait(C)` it goes to sleep, and must be woken by a\n",
    "future call to notify or broadcast. When a thread calls `signal(C),` a\n",
    "thread waiting on C is made eligible to return from `wait(),` and will\n",
    "do so as soon as it gets a chance to re-enter the monitor. On most\n",
    "systems threads waiting on C are picked in FIFO order, but this is not\n",
    "guaranteed. Finally, when a thread calls `broadcast(C),` all threads\n",
    "waiting on C are made eligible to return from `wait(),` and again will\n",
    "do so as soon as they are able to. If either notify or broadcast are\n",
    "called on a condition with no waiting threads, nothing will happen and\n",
    "no error will occur. Unlike calling `signal` on a semaphore with a\n",
    "positive count, the call won't be \"saved up\" for future calls to `wait`.\n",
    "And unlike unlocking a free mutex, it won't result in an error.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\scriptsize\" xleftmargin=\"0in\" framexleftmargin=\"0in\" multicols=\"2\" frame=\"none\"}\n",
    "monitor weighted_bb:\n",
    "    condition C_put, C_space, C_get\n",
    "    total = 0\n",
    "    space_needed = 0\n",
    "    buffer\n",
    "\n",
    "    method put(item):\n",
    "1       while space_needed > 0\n",
    "1           wait(C_put)\n",
    "        space_needed = item.weight\n",
    "2       while item.weight + total > max\n",
    "2           wait(C_space)\n",
    "        buffer.add_tail(item)\n",
    "        total = total + item.weight\n",
    "4       signal(C_get)\n",
    "1       space_needed = 0\n",
    "1       signal(C_put)\n",
    "\n",
    "    method get():\n",
    "3       while total == 0\n",
    "3           wait(C_get)\n",
    "        item = buffer.remove_head()\n",
    "        total = total - item.weight\n",
    "2       if total + space_needed <= max\n",
    "2           signal(C_space)\n",
    "        return item\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Here we see a monitor implementation of the weighted bounded buffer.\n",
    "Despite the increased complexity of the problem, this solution is only\n",
    "slightly longer than the semaphore solution to the simpler problem. A\n",
    "more detailed description of its operation:\n",
    "\n",
    "\\(1\\) The lines marked 1 serve as \"gatekeepers\": only one thread at a\n",
    "time can be executing the lines in the middle, including the\n",
    "`wait(C_space)` call. After leaving this section of code we signal the\n",
    "next waiting thread, if any.\n",
    "\n",
    "\\(2\\) Here a thread calling `put()` waits for space, and `get()` wakes\n",
    "it up if it has created enough space by removing an object.\n",
    "\n",
    "\\(3\\) Here a thread calling `get()` waits for an item if the buffer is\n",
    "empty, and is signalled by a thread at (4) calling `put().` Note that\n",
    "this interaction is simpler, because (as in the simple bounded-buffer\n",
    "case) there is a one-to-one relationship between items and calls to\n",
    "`get()`.\n",
    "\n",
    "## Using Conditions\n",
    "\n",
    "Like many programming features, there are different ways to use\n",
    "condition variables, and some of them are \"better\" than others, being\n",
    "easier to understand, write correctly, and debug. In this class we teach\n",
    "the following rule for using them:\n",
    "\n",
    "::: itemize*\n",
    "Each condition $C$ is associated with a boolean predicate $P$, and that\n",
    "condition is used in \"guards\" of the form `while (not P) wait(C)`, so\n",
    "that after the guard has been executed the invariant $P$ is true.\n",
    ":::\n",
    "\n",
    "In the example above, for instance, `C_space` is associated with the\n",
    "predicate $item.weight + total \\le max$, or in other words that there is\n",
    "enough room for the item. If there isn't then we wait; immediately after\n",
    "passing these two lines (marked 2 in the listing) we can be sure that\n",
    "there is indeed enough room.\n",
    "\n",
    "How can we be sure? If the predicate is true, and we don't have to wait,\n",
    "the answer is trivial. In the other case, we need to make sure that\n",
    "every piece of code which *might* make the predicate become true checks\n",
    "it, and if the predicate actually *has* become true it signals the\n",
    "associated condition variable.\n",
    "\n",
    "Note that this association only exists in the mind of the programmer,\n",
    "and is not enforced in any way by the programming language.\n",
    "Multithreaded programming would be much easier if we could just wait on\n",
    "the boolean predicate itself, but no one has yet invented a way to do\n",
    "this efficiently. Instead the programmer is responsible for the job of\n",
    "identifying what other pieces of code might make the predicate become\n",
    "true, with the resulting bugs if you miss any cases.\n",
    "\n",
    "**`while (condition)` vs `if (condition)`**: In\n",
    "[\\[fig:sync:wbb\\]](#fig:sync:wbb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:wbb\"} it would be nice if we could just call\n",
    "[wait(C_put)](wait(C_put)){.uri} or [wait(C_space)](wait(C_space)){.uri}\n",
    "and assume that the associated predicate is true after returning from\n",
    "wait. Unfortunately, it's not really possible, or at least not\n",
    "efficiently---even if mutexes and condition variables preserve FIFO\n",
    "ordering, there's often a window between when a thread calls\n",
    "[signal(C)](signal(C)){.uri} and the thread blocked in\n",
    "[wait(C)](wait(C)){.uri} returns, where a third thread can call the\n",
    "monitor method and grab the monitor mutex before the second thread is\n",
    "able to acquire it while returning from [wait(C)](wait(C)){.uri}.\n",
    "\n",
    "To handle this race condition we loop checking the predicate and waiting\n",
    "on the condition variable. In the (very rare) case where another thread\n",
    "entered the monitor while we were waking up, and e.g. grabbed whatever\n",
    "thing or resource we were waiting for, we go back to sleep and wait for\n",
    "another one.\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d908b9-9f11-4cbd-b78c-fbfbbc5d151e",
   "metadata": {},
   "source": [
    "### Implementing Monitors\n",
    "\n",
    "So far we've described monitors as a language feature, but if you look\n",
    "at the languages in use today you won't find the 'monitor' keyword\n",
    "anywhere. Java has very limited direct support for monitors---a\n",
    "synchronized class is essentially a monitor with a single condition\n",
    "variable, accessed implicitly via `acquire()` and `release()`. In\n",
    "general, however, you have to implement monitors yourself, using some\n",
    "sort of condition variable object supplied by the operating system or\n",
    "thread library.\n",
    "\n",
    "POSIX threads[^11]: This threading package, provided on Unix-like\n",
    "systems such as Linux and OSX, provides the following types and\n",
    "functions we can use:\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" frame=\"none\"}\n",
    "pthread_mutex_t mutex\n",
    "      pthread_mutex_lock(mutex)\n",
    "      pthread_mutex_unlock(mutex)\n",
    "      pthread_cond_t  cond\n",
    "      pthread_cond_wait(cond, mutex)\n",
    "      pthread_cond_signal(cond)\n",
    "      pthread_cond_broadcast(cond)\n",
    "```\n",
    "\n",
    "Since the language doesn't provide an implicit monitor mutex, we\n",
    "allocate an *explicit* per-object mutex, locking it on entry to each\n",
    "method and unlocking before returning from the method. Condition\n",
    "variables are also provided directly, e.g. by the pthread_cond_create\n",
    "function; however the thread library cannot know what object instance\n",
    "and mutex a condition variable is associated with, and so we have to\n",
    "pass the mutex explicitly when we wait on a condition. More precisely,\n",
    "the translation (as shown in\n",
    "[\\[lst:mon:posix\\]](#lst:mon:posix){reference-type=\"autoref\"\n",
    "reference=\"lst:mon:posix\"}) is:\n",
    "\n",
    "::: enumerate*\n",
    "(implicit mutex) : create a per-instance mutex `m` which is locked on\n",
    "entry to each method and unlocked on exit. (being careful with multiple\n",
    "exits, or worse yet exceptions)\n",
    "\n",
    "condition variables : translate each to an instance variable of type\n",
    "`pthread_cond_t`\n",
    "\n",
    "`signal(C)`, `broadcast(C)` : `pthread_cond_signal(C)` and\n",
    "`pthread_cond_broadcast(C)`\n",
    "\n",
    "`wait(C)` : `pthread_cond_wait(C, m)` where `m` is the per-instance\n",
    "mutex.\n",
    ":::\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" multicols=\"2\" xleftmargin=\"0in\" framexleftmargin=\"0in\" frame=\"none\"}\n",
    "monitor myclass:\n",
    "    condition C1, C2\n",
    "\n",
    "    method m1():\n",
    "        C1.wait()\n",
    "        C2.signal()\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class myclass {\n",
    "private:\n",
    "    pthread_mutex_t m;\n",
    "    pthread_cond_t C1, C2;\n",
    "\n",
    "public:\n",
    "    void m1(void) {\n",
    "        pthread_mutex_lock(&m);\n",
    "        pthread_cond_wait(&C1, &m);\n",
    "        pthread_cond_signal(&C2);\n",
    "        pthread_mutex_unlock(&m);\n",
    "    }\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Note that for programming exercises in this class we may implement\n",
    "singleton objects in C, in which case we can simplify our implementation\n",
    "somewhat:\n",
    "\n",
    "::: itemize*\n",
    "Methods become functions, as there is no need to specify which object\n",
    "instance to apply a method to.\n",
    "\n",
    "Instance variables become global variables, because we only need one\n",
    "copy of them, but they must be shared between methods.\n",
    ":::\n",
    "\n",
    "``` {#lst:mon:single float=\"h\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" caption=\"Singleton monitor implementation in C.\" label=\"lst:mon:single\"}\n",
    "pthread_mutex_t m;\n",
    "pthread_cond_t C1, C2;\n",
    "void m1() {\n",
    "    pthread_mutex_lock(&m);\n",
    "    pthread_cond_wait(&C1, &m);\n",
    "    pthread_cond_signal(&C2);\n",
    "    pthread_mutex_unlock(&m);\n",
    "}\n",
    "```\n",
    "\n",
    "**Java:** In this case we use an instance of *ReentrantLock* (in\n",
    "java.util.concurrent.locks) as our mutex, with methods `lock` and\n",
    "`unlock`. Condition variables are associated with a ReentrantLock (i.e.\n",
    "mutex), so given a ReentrantLock $m$ created to be the per-object mutex,\n",
    "for each condition variable $C$ in the original monitor we create a\n",
    "Condition via m.newCondition(); operations on these conditions are\n",
    "*wait*, *notify*, and *notifyAll*.\n",
    "\n",
    "``` {#lst:mon:java float=\"\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" caption=\"Monitor implementation in Java\" label=\"lst:mon:java\"}\n",
    "import ReentrantLock from java.util.concurrent.locks;\n",
    "class myclass {\n",
    "    ReentrantLock m = new ReentrantLock();\n",
    "    Condition C1 = m.newCondition(), C2 = m.newCondition();\n",
    "\n",
    "    void m1() {\n",
    "        m.lock();\n",
    "        C1.wait();\n",
    "        C2.notify();\n",
    "        m.unlock();\n",
    "    }\n",
    "```\n",
    "\n",
    "**Python:** The module `threading` implements two classes, `Lock` and\n",
    "`Condition`, which we use as above. (note that the methods for\n",
    "`threading.Lock` are `acquire` and `release`) Like Java, conditions are\n",
    "associated with locks at the time of creation, so there is no need to\n",
    "remember to pass the mutex in the `wait()` function.\n",
    "\n",
    "``` {#lst:mon:python float=\"b\" basicstyle=\"\\\\ttfamily\\\\footnotesize\" caption=\"Monitor implementation in Python\" label=\"lst:mon:python\"}\n",
    "import threading\n",
    "class myclass:\n",
    "    def __init__(self):\n",
    "        self.m = threading.Lock()\n",
    "        self.C1 = threading.Condition(self.m)\n",
    "        self.C2 = threading.Condition(self.m)\n",
    "\n",
    "    def m1(self):\n",
    "        self.m.acquire()\n",
    "        self.C1.wait()\n",
    "        self.C2.notify()\n",
    "        self.m.release()\n",
    "```\n",
    "\n",
    "#### Review Questions\n",
    "\n",
    "::: enumerate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e084b-fd53-421b-8588-49276050cc89",
   "metadata": {},
   "source": [
    "## Graphical Notation\n",
    "\n",
    "Reasoning about multi-threaded programs is harder than single-threaded\n",
    "ones. For single-threaded programs most people can visualize how program\n",
    "execution moves from one line of code to another; however in the\n",
    "multi-threaded case you have to be aware of many possible copies of the\n",
    "same code, each possibly executing a different line.\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-method.png){width=\"10%\"}\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-choice.png){width=\"18%\"}\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-cond.png){width=\"18%\"}\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-signal.png){width=\"38%\"}\n",
    "\n",
    "In [\\[fig:sync:graphic\\]](#fig:sync:graphic){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:graphic\"} we see the elements of a graphical\n",
    "representation for a monitor, which allows us to see more directly how\n",
    "different threads interact in the execution of a multi-threaded program.\n",
    "Each method is represented by a path (a), which may involve decisions\n",
    "(b), waiting on conditions (c), and signalling those conditions (d).\n",
    "\n",
    "![Graphical representation for weighted bounded buffer solution shown in\n",
    "[\\[fig:sync:wbb\\]](#fig:sync:wbb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:wbb\"}](../images/pb-figures/sync/sync-pic1.png){#fig:sync:gwbb\n",
    "width=\"70%\"}\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-pic2.png){height=\"0.27\\\\textheight\"}\\\n",
    "![image](../images/pb-figures/sync/sync-pic3.png){height=\"0.27\\\\textheight\"}\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "\\\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "![image](../images/pb-figures/sync/sync-pic4.png){height=\"0.27\\\\textheight\"}\\\n",
    "![image](../images/pb-figures/sync/sync-pic5.png){height=\"0.27\\\\textheight\"}\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "In [\\[fig:sync:gwbb\\]](#fig:sync:gwbb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:gwbb\"} we see the weighted bounded buffer solution\n",
    "from [\\[fig:sync:wbb\\]](#fig:sync:wbb){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:wbb\"} represented in this graphical notation, and in\n",
    "[\\[fig:sync:gwbb2\\]](#fig:sync:gwbb2){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:gwbb2\"} we see multiple threads moving through this\n",
    "representation.\n",
    "\n",
    "(Note that the figures have been simplified slightly by using\n",
    "`if (!P) wait(C);` instead of `while (!P) wait(C)`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2665c-7364-4768-92c6-5e1136631200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "803ad2ad-ec5d-45e5-a739-df7937c0be61",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Most of the synchronization techniques discussed in this chapter are\n",
    "applicable to multi-threaded application programs, rather than operating\n",
    "systems themselves; however synchronization and the prevention of race\n",
    "conditions are still key techniques within an OS.\n",
    "\n",
    "**Condition variables and **signal()****: The I/O wait mechanism is an\n",
    "example of this. When the shell invokes the `read` system call to read\n",
    "characters from the keyboard, the process is removed from the active\n",
    "list and placed on a wait queue in the kernel; the keyboard interrupt\n",
    "handler then wakes a process waiting on this queue when a character is\n",
    "received. The semantics of this I/O wait queue and the operation to wake\n",
    "a process from it are identical to those of a condition variable with\n",
    "`wait` and `signal`. (the design choices are similar, too. Simple\n",
    "operating systems may use the equivalent of `broadcast`, waking all\n",
    "processes waiting on any sort of I/O and having each of them re-check\n",
    "the condition they are waiting on before going to sleep, while for\n",
    "highest performance more complete OSes have separate wait queues per I/O\n",
    "source, and when data arrives a single waiting process will be woken.)\n",
    "\n",
    "**Mutexes**: An operating system is full of potential race conditions,\n",
    "and heavy use is made of locking mechanisms to prevent errors or\n",
    "crashes. Asynchronous events can occur due to timer or I/O interrupts,\n",
    "and on a multi-core CPU there can be OS code running on multiple cores\n",
    "at the same time. In either case it is essential to protect key OS data\n",
    "structures, such as the list of active processes, which is typically\n",
    "implemented as a singly- or doubly-linked list.\n",
    "\n",
    "Data structures such as this will typically be protected by a\n",
    "combination of spinlocks and disabling interrupts---e.g. to modify the\n",
    "active process list, OS code will (1) disable interrupts, (2) acquire a\n",
    "spinlock which guards that list, (3) perform the modifications, (4)\n",
    "release the spinlock and (5) re-enable interrupts. (Interrupts are\n",
    "typically disabled while an interrupt handler executes, so when\n",
    "accessing these data structures from an interrupt handler it is\n",
    "sufficient to acquire the spinlock.)\n",
    "\n",
    "When switching to the next runnable process, it's necessary to protect\n",
    "not only the active process list, so that it doesn't get corrupted, but\n",
    "to also protect the variable identifying the current process on each\n",
    "CPU, to prevent two processes from being assigned to the same CPU at the\n",
    "same time. A simple way of doing this is to have a `schedule()` function\n",
    "which is called under a lock, and which pops the next runnable process\n",
    "off the active list, makes it the current process, and switches to it;\n",
    "e.g. an implementation using simple round-robin scheduling might be as\n",
    "shown in\n",
    "[\\[fig:sync:rrsched\\]](#fig:sync:rrsched){reference-type=\"autoref\"\n",
    "reference=\"fig:sync:rrsched\"}.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "``` {basicstyle=\"\\\\ttfamily\\\\footnotesize\" xleftmargin=\"0in\" framexleftmargin=\"0in\" multicols=\"2\" frame=\"none\"}\n",
    "[e.g. yield:]\n",
    "       ...\n",
    "    lock(plist_lock);\n",
    "    schedule();\n",
    "    unlock(plist_lock);\n",
    "       ...\n",
    "\n",
    "schedule() {\n",
    "    active_tail->next = current;\n",
    "    active_tail = current;\n",
    "    current = active_head;\n",
    "    active_head = active_head->next; \n",
    "    switch_to(current);\n",
    "}\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Note that the lock can't be \"encapsulated\" within `schedule` and hidden\n",
    "from other code, because special handling is required when creating\n",
    "processes---when a new process begins it will execute a \"trampoline\"\n",
    "function, rather than the second half of the `schedule` function, and\n",
    "must drop the lock that was acquired when switching to it.\n",
    "\n",
    "Finally, deadlocks are a risk when implementing an operating system. In\n",
    "many cases the objects of contention are not mutexes themselves, but\n",
    "resources such as pages of memory E.g. consider the case[^12] where a\n",
    "process tries to allocate a page of memory when (almost) all pages are\n",
    "in use. The OS finds a page it can \"steal\" from another process after\n",
    "writing its contents to disk; however if that page is associated with a\n",
    "network file, the OS may need to temporarily allocate another page of\n",
    "memory in order to send the network message to write it back.\n",
    "\n",
    "The solution to this is to reserve the last few blocks of memory to\n",
    "various high-priority uses. This works in much the same way as lock\n",
    "ranking, because the original request is made at low priority (i.e. by\n",
    "the process) and thus can't acquire and hold the resources which would\n",
    "be needed by the higher-priority page-out and networking tasks.\n",
    "\n",
    "### Answers to Review Questions\n",
    "\n",
    "::: compactenum\n",
    "in synchro:1,synchro:2,synchro:3,synchro:4,synchro:5,synchro:6\n",
    ":::\n",
    "\n",
    "[^1]: The simplest way to do this is to only allow single-threaded\n",
    "    programs. This was the case for almost all operating systems until\n",
    "    the mid-90s; multi-threading and locking were obscure concerns which\n",
    "    only kernel programmers had to worry about\n",
    "\n",
    "[^2]: The name *atom* derives from the ancient Greek word for\n",
    "    *indivisible*, and so is something that can't be cut or divided. (or\n",
    "    at least couldn't be until the physicists got to work on it) An\n",
    "    *atomic operation* cannot be divided into parts by another\n",
    "    operation.\n",
    "\n",
    "[^3]: As opposed to [yield](yield){.uri}, which adds the current thread\n",
    "    to the end of the active queue before performing the same steps.\n",
    "\n",
    "[^4]: Another such instruction is Compare And Swap (e.g. the Intel\n",
    "    CMPXCHG instruction), which only performs the swap if the value in\n",
    "    memory matches an expected value.\n",
    "\n",
    "[^5]: Sort of. On massively multi-core machines---e.g. 72 cores is a\n",
    "    common number nowadays---highly contented locks are still\n",
    "    inefficient, as waiting for 71 other CPUs to do a few instructions\n",
    "    each can take a while.\n",
    "\n",
    "[^6]: which means \"for teaching purposes only\", i.e. not necessarily\n",
    "    practical.\n",
    "\n",
    "[^7]: Note how locks complicate control flow---you have to make sure\n",
    "    that all locks are released, even in failure cases.\n",
    "\n",
    "[^8]: In particular, for debugging purposes many implementations (such\n",
    "    as the POSIX threads implementation in Linux) require that a mutex\n",
    "    be unlocked by the same thread that locked it.\n",
    "\n",
    "[^9]: Not that it really matters, as a well-behaved program probably\n",
    "    wouldn't do this.\n",
    "\n",
    "[^10]: Or at least any that can be solved by other techniques described\n",
    "    in this text.\n",
    "\n",
    "[^11]: The same threading model is available in C11, with slightly\n",
    "    different names---e.g. mutexes are of type [mtx_t](mtx_t){.uri},\n",
    "    with functions [mtx_lock](mtx_lock){.uri} and\n",
    "    [mtx_unlock](mtx_unlock){.uri}\n",
    "\n",
    "[^12]: Yes, I know we haven't covered some of the parts of this yet, but\n",
    "    we'll get to them in the next chapter\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52caa39-39bc-407f-865c-65fec4d1379a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
